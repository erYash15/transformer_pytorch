{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "import spacy\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import math\n",
    "\n",
    "# Define model components (as per user's code with submodules)\n",
    "class InputEmbeddings(nn.Module):\n",
    "    def __init__(self, d_model: int, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, seq_len: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class MultiHeadAttentionBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, h: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_o = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        batch_size = q.size(0)\n",
    "        q = self.w_q(q).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
    "        k = self.w_k(k).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
    "        v = self.w_v(v).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask, -1e9)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        output = torch.matmul(attn_weights, v).transpose(1, 2).contiguous().view(batch_size, -1, self.h * self.d_k)\n",
    "        return self.w_o(output)\n",
    "\n",
    "class FeedForwardBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, self_attention: MultiHeadAttentionBlock, ff: FeedForwardBlock, dropout: float):\n",
    "        super().__init__()\n",
    "        self.self_attention = self_attention\n",
    "        self.ff = ff\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        _x = self.norm1(x)\n",
    "        x = x + self.dropout(self.self_attention(_x, _x, _x, src_mask))\n",
    "        _x = self.norm2(x)\n",
    "        x = x + self.dropout(self.ff(_x))\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model: int, blocks: nn.ModuleList):\n",
    "        super().__init__()\n",
    "        self.blocks = blocks\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for block in self.blocks:\n",
    "            x = block(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, self_attention: MultiHeadAttentionBlock, cross_attention: MultiHeadAttentionBlock, ff: FeedForwardBlock, dropout: float):\n",
    "        super().__init__()\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.ff = ff\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        _x = self.norm1(x)\n",
    "        x = x + self.dropout(self.self_attention(_x, _x, _x, tgt_mask))\n",
    "        _x = self.norm2(x)\n",
    "        x = x + self.dropout(self.cross_attention(_x, encoder_output, encoder_output, src_mask))\n",
    "        _x = self.norm3(x)\n",
    "        x = x + self.dropout(self.ff(_x))\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model: int, blocks: nn.ModuleList):\n",
    "        super().__init__()\n",
    "        self.blocks = blocks\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        for block in self.blocks:\n",
    "            x = block(x, encoder_output, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class ProjectionLayer(nn.Module):\n",
    "    def __init__(self, d_model: int, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.log_softmax(self.proj(x), dim=-1)\n",
    "\n",
    "# Original Transformer class provided by user\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size: int, tgt_vocab_size: int, src_seq_len: int, tgt_seq_len: int, d_model: int=512, N: int=6, h: int=8, dropout: float=0.1, d_ff: int=2048):\n",
    "        super().__init__()\n",
    "        self.src_embed = InputEmbeddings(d_model, src_vocab_size)\n",
    "        self.tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\n",
    "        self.src_pos = PositionalEncoding(d_model, src_seq_len, dropout)\n",
    "        self.tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)\n",
    "        \n",
    "        encoder_blocks = []\n",
    "        for _ in range(N):\n",
    "            encoder_self_attention = MultiHeadAttentionBlock(d_model, h, dropout)\n",
    "            ff = FeedForwardBlock(d_model, d_ff, dropout)\n",
    "            encoder_block = EncoderBlock(d_model, encoder_self_attention, ff, dropout)\n",
    "            encoder_blocks.append(encoder_block)\n",
    "        self.encoder = Encoder(d_model, nn.ModuleList(encoder_blocks))\n",
    "        \n",
    "        decoder_blocks = []\n",
    "        for _ in range(N):\n",
    "            self_attention = MultiHeadAttentionBlock(d_model, h, dropout)\n",
    "            cross_attention = MultiHeadAttentionBlock(d_model, h, dropout)\n",
    "            ff = FeedForwardBlock(d_model, d_ff, dropout)\n",
    "            decoder_block = DecoderBlock(d_model, self_attention, cross_attention, ff, dropout)\n",
    "            decoder_blocks.append(decoder_block)\n",
    "        self.decoder = Decoder(d_model, nn.ModuleList(decoder_blocks))\n",
    "        \n",
    "        self.projection = ProjectionLayer(d_model, tgt_vocab_size)\n",
    "        \n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        src = self.src_embed(src)\n",
    "        src = self.src_pos(src)\n",
    "        return self.encoder(src, src_mask)\n",
    "    \n",
    "    def decode(self, encoder_output, src_mask, tgt, tgt_mask):\n",
    "        tgt = self.tgt_embed(tgt)\n",
    "        tgt = self.tgt_pos(tgt)\n",
    "        return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n",
    "    \n",
    "    def project(self, x):\n",
    "        return self.projection(x)\n",
    "    \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        encoder_output = self.encode(src, src_mask)\n",
    "        decoder_output = self.decode(encoder_output, src_mask, tgt, tgt_mask)\n",
    "        return self.project(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import math\n",
    "import re\n",
    "\n",
    "# Custom simple tokenizer (whitespace-based with basic punctuation handling)\n",
    "def simple_tokenizer(text):\n",
    "    return re.findall(r'\\w+|[^\\w\\s]', text.lower())\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data, src_vocab, tgt_vocab, max_len=100):\n",
    "        self.data = data\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]['translation']\n",
    "        \n",
    "        # Source (English) processing\n",
    "        src_tokens = ['<bos>'] + simple_tokenizer(item['en'])[:self.max_len-2] + ['<eos>']\n",
    "        src_tokens += ['<pad>'] * (self.max_len - len(src_tokens))\n",
    "        \n",
    "        # Target (Italian) processing\n",
    "        tgt_tokens = simple_tokenizer(item['it'])[:self.max_len-2]\n",
    "        tgt_input = ['<bos>'] + tgt_tokens\n",
    "        tgt_output = tgt_tokens + ['<eos>']\n",
    "        \n",
    "        # Padding\n",
    "        tgt_input += ['<pad>'] * (self.max_len - len(tgt_input))\n",
    "        tgt_output += ['<pad>'] * (self.max_len - len(tgt_output))\n",
    "        \n",
    "        return {\n",
    "            'src': torch.tensor([self.src_vocab[tok] for tok in src_tokens], dtype=torch.long),\n",
    "            'tgt_input': torch.tensor([self.tgt_vocab[tok] for tok in tgt_input], dtype=torch.long),\n",
    "            'tgt_output': torch.tensor([self.tgt_vocab[tok] for tok in tgt_output], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset('opus_books', 'en-it')['train'].train_test_split(0.2)\n",
    "train_data = dataset['train']\n",
    "valid_data = dataset['test']\n",
    "\n",
    "# Build vocabulary from training data\n",
    "def yield_tokens(data_iter, lang):\n",
    "    for item in data_iter:\n",
    "        yield simple_tokenizer(item['translation'][lang])\n",
    "\n",
    "src_vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(train_data, 'en'),\n",
    "    specials=['<pad>', '<bos>', '<eos>']\n",
    ")\n",
    "tgt_vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(train_data, 'it'),\n",
    "    specials=['<pad>', '<bos>', '<eos>']\n",
    ")\n",
    "src_vocab.set_default_index(src_vocab['<pad>'])\n",
    "tgt_vocab.set_default_index(tgt_vocab['<pad>'])\n",
    "\n",
    "# Create datasets\n",
    "max_len = 100\n",
    "batch_size = 32\n",
    "train_dataset = TranslationDataset(train_data, src_vocab, tgt_vocab, max_len)\n",
    "valid_dataset = TranslationDataset(valid_data, src_vocab, tgt_vocab, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Keep all model components identical from your original code...]\n",
    "\n",
    "# Training setup remains the same\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Transformer(\n",
    "    src_vocab_size=len(src_vocab),\n",
    "    tgt_vocab_size=len(tgt_vocab),\n",
    "    src_seq_len=max_len,\n",
    "    tgt_seq_len=max_len,\n",
    "    d_model=512,\n",
    "    N=2,\n",
    "    h=8\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [Rest of training loop and validation remains identical...]\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab['<pad>'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "class WarmupScheduler:\n",
    "    def __init__(self, d_model, warmup_steps, optimizer):\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.optimizer = optimizer\n",
    "        self.step_num = 0\n",
    "    \n",
    "    def step(self):\n",
    "        self.step_num += 1\n",
    "        lr = (self.d_model ** -0.5) * min(self.step_num ** -0.5, self.step_num * (self.warmup_steps ** -1.5))\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "scheduler = WarmupScheduler(512, 4000, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask functions\n",
    "def create_mask(src, tgt_input, src_pad_idx, tgt_pad_idx):\n",
    "    src_mask = (src == src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "    tgt_pad_mask = (tgt_input == tgt_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "    tgt_len = tgt_input.size(1)\n",
    "    tgt_sub_mask = torch.triu(torch.ones((tgt_len, tgt_len), device=device)).bool()\n",
    "    tgt_mask = tgt_pad_mask | tgt_sub_mask\n",
    "    return src_mask, tgt_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m output \u001b[38;5;241m=\u001b[39m model(src, tgt_input, src_mask, tgt_mask)\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), tgt_output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.pyenv/versions/pfenv/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/pfenv/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Wrap train_loader with tqdm for progress bar\n",
    "    train_iterator = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "    for batch in train_iterator:\n",
    "        src = batch['src'].to(device)\n",
    "        tgt_input = batch['tgt_input'].to(device)\n",
    "        tgt_output = batch['tgt_output'].to(device)\n",
    "        \n",
    "        src_mask, tgt_mask = create_mask(src, tgt_input, src_vocab['<pad>'], tgt_vocab['<pad>'])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt_input, src_mask, tgt_mask)\n",
    "        loss = criterion(output.view(-1, output.size(-1)), tgt_output.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        # Update progress bar with current loss\n",
    "        train_iterator.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Validation\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "# Wrap valid_loader with tqdm for progress bar\n",
    "val_iterator = tqdm(valid_loader, desc=\"Validation\", leave=False)\n",
    "with torch.no_grad():\n",
    "    for batch in val_iterator:\n",
    "        src = batch['src'].to(device)\n",
    "        tgt_input = batch['tgt_input'].to(device)\n",
    "        tgt_output = batch['tgt_output'].to(device)\n",
    "        \n",
    "        src_mask, tgt_mask = create_mask(src, tgt_input, src_vocab['<pad>'], tgt_vocab['<pad>'])\n",
    "        \n",
    "        output = model(src, tgt_input, src_mask, tgt_mask)\n",
    "        loss = criterion(output.view(-1, output.size(-1)), tgt_output.view(-1))\n",
    "        val_loss += loss.item()\n",
    "        # Update progress bar with current loss\n",
    "        val_iterator.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "print(f\"Validation Loss: {val_loss/len(valid_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 25865\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 6467\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].train_test_split(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "import spacy\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import math\n",
    "\n",
    "# Define model components (as per user's code with submodules)\n",
    "class InputEmbeddings(nn.Module):\n",
    "    def __init__(self, d_model: int, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, seq_len: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class MultiHeadAttentionBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, h: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_o = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        batch_size = q.size(0)\n",
    "        q = self.w_q(q).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
    "        k = self.w_k(k).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
    "        v = self.w_v(v).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask, -1e9)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        output = torch.matmul(attn_weights, v).transpose(1, 2).contiguous().view(batch_size, -1, self.h * self.d_k)\n",
    "        return self.w_o(output)\n",
    "\n",
    "class FeedForwardBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, self_attention: MultiHeadAttentionBlock, ff: FeedForwardBlock, dropout: float):\n",
    "        super().__init__()\n",
    "        self.self_attention = self_attention\n",
    "        self.ff = ff\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        _x = self.norm1(x)\n",
    "        x = x + self.dropout(self.self_attention(_x, _x, _x, src_mask))\n",
    "        _x = self.norm2(x)\n",
    "        x = x + self.dropout(self.ff(_x))\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model: int, blocks: nn.ModuleList):\n",
    "        super().__init__()\n",
    "        self.blocks = blocks\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for block in self.blocks:\n",
    "            x = block(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, self_attention: MultiHeadAttentionBlock, cross_attention: MultiHeadAttentionBlock, ff: FeedForwardBlock, dropout: float):\n",
    "        super().__init__()\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.ff = ff\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        _x = self.norm1(x)\n",
    "        x = x + self.dropout(self.self_attention(_x, _x, _x, tgt_mask))\n",
    "        _x = self.norm2(x)\n",
    "        x = x + self.dropout(self.cross_attention(_x, encoder_output, encoder_output, src_mask))\n",
    "        _x = self.norm3(x)\n",
    "        x = x + self.dropout(self.ff(_x))\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model: int, blocks: nn.ModuleList):\n",
    "        super().__init__()\n",
    "        self.blocks = blocks\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        for block in self.blocks:\n",
    "            x = block(x, encoder_output, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class ProjectionLayer(nn.Module):\n",
    "    def __init__(self, d_model: int, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.log_softmax(self.proj(x), dim=-1)\n",
    "\n",
    "# Original Transformer class provided by user\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size: int, tgt_vocab_size: int, src_seq_len: int, tgt_seq_len: int, d_model: int=512, N: int=6, h: int=8, dropout: float=0.1, d_ff: int=2048):\n",
    "        super().__init__()\n",
    "        self.src_embed = InputEmbeddings(d_model, src_vocab_size)\n",
    "        self.tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\n",
    "        self.src_pos = PositionalEncoding(d_model, src_seq_len, dropout)\n",
    "        self.tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)\n",
    "        \n",
    "        encoder_blocks = []\n",
    "        for _ in range(N):\n",
    "            encoder_self_attention = MultiHeadAttentionBlock(d_model, h, dropout)\n",
    "            ff = FeedForwardBlock(d_model, d_ff, dropout)\n",
    "            encoder_block = EncoderBlock(d_model, encoder_self_attention, ff, dropout)\n",
    "            encoder_blocks.append(encoder_block)\n",
    "        self.encoder = Encoder(d_model, nn.ModuleList(encoder_blocks))\n",
    "        \n",
    "        decoder_blocks = []\n",
    "        for _ in range(N):\n",
    "            self_attention = MultiHeadAttentionBlock(d_model, h, dropout)\n",
    "            cross_attention = MultiHeadAttentionBlock(d_model, h, dropout)\n",
    "            ff = FeedForwardBlock(d_model, d_ff, dropout)\n",
    "            decoder_block = DecoderBlock(d_model, self_attention, cross_attention, ff, dropout)\n",
    "            decoder_blocks.append(decoder_block)\n",
    "        self.decoder = Decoder(d_model, nn.ModuleList(decoder_blocks))\n",
    "        \n",
    "        self.projection = ProjectionLayer(d_model, tgt_vocab_size)\n",
    "        \n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        src = self.src_embed(src)\n",
    "        src = self.src_pos(src)\n",
    "        return self.encoder(src, src_mask)\n",
    "    \n",
    "    def decode(self, encoder_output, src_mask, tgt, tgt_mask):\n",
    "        tgt = self.tgt_embed(tgt)\n",
    "        tgt = self.tgt_pos(tgt)\n",
    "        return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n",
    "    \n",
    "    def project(self, x):\n",
    "        return self.projection(x)\n",
    "    \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        encoder_output = self.encode(src, src_mask)\n",
    "        decoder_output = self.decode(encoder_output, src_mask, tgt, tgt_mask)\n",
    "        return self.project(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MemoryMappedTable\n",
       "id: string\n",
       "translation: struct<en: string, it: string>\n",
       "  child 0, en: string\n",
       "  child 1, it: string\n",
       "----\n",
       "id: [[\"0\",\"1\",\"2\",\"3\",\"4\",...,\"995\",\"996\",\"997\",\"998\",\"999\"],[\"1000\",\"1001\",\"1002\",\"1003\",\"1004\",...,\"1995\",\"1996\",\"1997\",\"1998\",\"1999\"],...,[\"31000\",\"31001\",\"31002\",\"31003\",\"31004\",...,\"31995\",\"31996\",\"31997\",\"31998\",\"31999\"],[\"32000\",\"32001\",\"32002\",\"32003\",\"32004\",...,\"32327\",\"32328\",\"32329\",\"32330\",\"32331\"]]\n",
       "translation: [\n",
       "  -- is_valid: all not null\n",
       "  -- child 0 type: string\n",
       "[\"Source: Project Gutenberg\",\"Jane Eyre\",\"Charlotte Bronte\",\"CHAPTER I\",\"There was no possibility of taking a walk that day.\",...,\"\"I am afraid I never shall do that.\"\",\"\"Why?\"\",\"\"Because I have been wrongly accused; and you, ma'am, and everybody else, will now think me wicked.\"\",\"\"We shall think you what you prove yourself to be, my child.\",\"Continue to act as a good girl, and you will satisfy us.\"\"]\n",
       "  -- child 1 type: string\n",
       "[\"Source: www.liberliber.it/Audiobook available here\",\"Jane Eyre\",\"Charlotte Brontë\",\"PARTE PRIMA\",\"I. In quel giorno era impossibile passeggiare.\",...,\"— Credo di non potermi consolare mai.\",\"— Perché?\",\"— Perché sono stata ingiustamente accusata dinanzi a tutti, e voi stessa, signora, mi credete colpevole.\",\"— Noi crederemo ciò che vedremo e ci formeremo un'opinione sulla vostra condotta, bambina mia.\",\"Continuate ad esser buona, e mi contenterete.\"],\n",
       "  -- is_valid: all not null\n",
       "  -- child 0 type: string\n",
       "[\"\"Shall I, Miss Temple?\"\",\"\"You will,\" said she, passing her arm round me. \"And now tell me who is the lady whom Mr. Brocklehurst called your benefactress?\"\",\"\"Mrs. Reed, my uncle's wife. My uncle is dead, and he left me to her care.\"\",\"\"Did she not, then, adopt you of her own accord?\"\",\"\"No, ma'am; she was sorry to have to do it: but my uncle, as I have often heard the servants say, got her to promise before he died that she would always keep me.\"\",...,\"Now, when any vicious simpleton excites my disgust by his paltry ribaldry, I cannot flatter myself that I am better than he: I am forced to confess that he and I are on a level.\",\"I wish I had stood firm--God knows I do!\",\"Dread remorse when you are tempted to err, Miss Eyre; remorse is the poison of life.\"\",\"\"Repentance is said to be its cure, sir.\"\",\"\"It is not its cure. Reformation may be its cure; and I could reform--I have strength yet for that--if--but where is the use of thinking of it, hampered, burdened, cursed as I am?\"]\n",
       "  -- child 1 type: string\n",
       "[\"— Davvero, signorina Temple?\",\"— Sì, — rispose cingendomi con un braccio. — E ora ditemi chi è quella signora, che il pastore chiama la vostra benefattrice.\",\"— È la signora Reed, la moglie di mio zio; egli è morto e mi ha lasciata affidata a lei.\",\"— Ella non vi ha dunque liberamente adottata?\",\"— No, la signora Reed era in collera per questo, ma mio zio, per quanto mi ha detto spesso la servitù, le aveva fatto promettere, morendo, di tenermi sempre presso di sé.\",...,\"\"Sono costretto a riconoscere che lui ed io siamo allo stesso livello.\",\"\"Perché non sono rimasto saldo?\",\"Dio sa se lo desidero! \"Temete i rimorsi, quando sarete tentata di soccombere, signorina Eyre: il rimorso è il veleno della vita.\",\"— Si dice che il pentimento ne sia il rimedio, signore.\",\"— No, il solo rimedio è una condotta migliore, e potrei giungervi; ho ancora forza sufficiente, se.... Ma perché pensarvi, affranto e maledetto come sono?\"],\n",
       "...,\n",
       "  -- is_valid: all not null\n",
       "  -- child 0 type: string\n",
       "[\"He might have got back by this time; but her calculations might be incorrect, and again she began trying to remember when he had left and reckoning the minutes.\",\"Just as she was going to compare her watch with the large clock some one drove up.\",\"Glancing out of the window she saw his calèche.\",\"But no one came upstairs and she heard voices below.\",\"Her messenger had returned in the carriage.\",...,\"But however I may screw my eyes and strain my sight, I cannot help seeing it round and limited, and despite my knowledge of it as limitless space I am indubitably right when I see a firm blue vault, and more right than when I strain to see beyond it.'\",\"Levin ceased to think, and only as it were hearkened to mystic voices that seemed to be joyously and earnestly discussing something.\",\"'Can this really be faith?' he wondered, afraid to believe in his happiness. 'My God, I thank Thee!' he uttered, repressing his rising sobs, and wiping away with both hands the tears that filled his eyes.\",\"CHAPTER XIV\",\"LEVIN LOOKED STRAIGHT BEFORE HIM, and saw the herd of cattle and then his trap and his horse Raven and the coachman who, having driven up to the cattle, was speaking to the herdsman; after that, close by, he heard the sound of wheels and the snorting of a well-fed horse; but he was so engrossed in his thoughts that he did not wonder why the coachman was coming for him.\"]\n",
       "  -- child 1 type: string\n",
       "[\"Ma il calcolo poteva non essere giusto, ed ella si diede a ricordare nuovamente quando era andato via, e a calcolare i minuti.\",\"Mentre si allontanava verso la pendola grande per controllare l’ora, qualcuno giunse in vettura.\",\"Guardando dalla finestra vide il carrozzino di lui.\",\"Ma nessuno saliva la scala e giù si sentivano delle voci.\",\"Era l’inserviente che tornava col carrozzino.\",...,\"Ma per quanto socchiuda gli occhi e sforzi la vista, non posso non vederlo rotondo e limitato, e, malgrado la mia conoscenza dello spazio infinito, ho senza dubbio alcuno ragione quando vedo una solida volta azzurra, e ho più ragione che non quando mi sforzo di vedere al di là di essa”.\",\"Levin cessò di pensare e pareva soltanto prestare ascolto alle voci misteriose che, con gioia e con affanno, parlavano fra di loro di una certa cosa.\",\"“È forse questa la fede? — pensò, temendo di credere alla propria felicità. — Dio mio, Ti ringrazio!” egli pronunciò, soffocando i singhiozzi che salivano e asciugando con tutte e due le mani le lacrime di cui gli s’erano riempiti gli occhi.\",\"XIV\",\"Levin guardava dinanzi a sé e vedeva il gregge, poi il suo calesse al quale era attaccato Voronoj, e il cocchiere che, avvicinatosi al gregge, diceva qualcosa al pastore; sentì poi vicino a sé il suono delle ruote e lo sbuffare del cavallo ben pasciuto; ma era così assorto nei suoi pensieri che non suppose neppure perché il cocchiere venisse verso di lui.\"],\n",
       "  -- is_valid: all not null\n",
       "  -- child 0 type: string\n",
       "[\"That occurred to him only when the coachman drove up and called to him.\",\"'The mistress has sent me!\",\"Your brother and another gentleman have come!'\",\"Levin got into the trap and took the reins.\",\"As if just awakened from a dream, it was long before he could collect his thoughts.\",...,\"'No, I had better not tell her,' he thought when she had passed out before him. 'It is a secret, necessary and important for me alone, and inexpressible in words.'\",\"'This new feeling has not changed me, has not rendered me happy, nor suddenly illuminated me as I dreamt it would, but is just like my feeling for my son.\",\"It has not been a surprise either.\",\"But be it faith or not – I do not know what it is – this feeling has also entered imperceptibly through suffering and is firmly rooted in my soul.\",\"'I shall still get angry with Ivan the coachman in the same way, shall dispute in the same way, shall inopportunely express my thoughts; there will still be a wall between my soul's holy of holies and other people; even my wife I shall still blame for my own fears and shall repent of it. My reason will still not understand why I pray, but I shall still pray, and my life, my whole life, independently of anything that may happen to me, is every moment of it no longer meaningless as it was before, but has an unquestionable meaning of goodness with which I have the power to invest it.'\"]\n",
       "  -- child 1 type: string\n",
       "[\"Se ne ricordò solo quando il cocchiere gli fu proprio accosto e lo chiamò.\",\"— Ha mandato la signora.\",\"Sono arrivati il fratello e anche un certo signore.\",\"Levin salì sul calesse e prese le redini.\",\"Come se si fosse svegliato da un sonno, Levin stentò a tornare in sé.\",...,\"“No, non bisogna parlare — egli pensò, quand’ella gli passò avanti. — È un segreto necessario, importante per me solo e inesprimibile a parole.\",\"Questo nuovo sentimento non mi ha cambiato, non mi ha reso felice, non mi ha rischiarato a un tratto, come sognavo, proprio come il sentimento per mio figlio.\",\"Anche qui non c’è stata nessuna sorpresa.\",\"E fede o non fede, non so cosa sia, ma questo sentimento è entrato in me egualmente inavvertito, attraverso la sofferenza, e si è fermato saldamente nell’anima.\",\"Mi arrabbierò sempre alla stessa maniera contro Ivan il cocchiere, sempre alla stessa maniera discuterò, esprimerò a sproposito le mie idee, ci sarà lo stesso muro fra il tempio dell’anima mia e quello degli altri, e perfino mia moglie accuserò sempre alla stessa maniera del mio spavento e ne proverò rimorso; sempre alla stessa maniera, non capirò con la ragione perché prego e intanto pregherò, ma la mia vita adesso, tutta la mia vita, indipendentemente da tutto quello che mi può accadere, ogni suo attimo, non solo non è più senza senso, come prima, ma ha un indubitabile senso di bene, che io ho il potere di trasfondere in essa!”.\"]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
