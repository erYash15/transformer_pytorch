{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Transformer Model Training Notebook\n","\n","This notebook demonstrates how to train a transformer model. We will go through the steps of setting up the environment, loading data, preprocessing, training the model, and evaluating its performance.\n","\n","However, Architecture is available in the github repo: **eryash15/transformer_pytorch**"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:38:46.784384Z","iopub.status.busy":"2024-06-26T21:38:46.783587Z","iopub.status.idle":"2024-06-26T21:39:04.131504Z","shell.execute_reply":"2024-06-26T21:39:04.130657Z","shell.execute_reply.started":"2024-06-26T21:38:46.784325Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-04-18 12:07:12.886152: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, random_split\n","\n","from datasets import load_dataset\n","from tokenizers import Tokenizer\n","from tokenizers.models import WordLevel\n","from tokenizers.trainers import WordLevelTrainer\n","from tokenizers.pre_tokenizers import Whitespace\n","\n","from pathlib import Path\n","\n","from torchmetrics.text import BLEUScore\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm.notebook import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:04.133698Z","iopub.status.busy":"2024-06-26T21:39:04.133109Z","iopub.status.idle":"2024-06-26T21:39:04.155122Z","shell.execute_reply":"2024-06-26T21:39:04.154313Z","shell.execute_reply.started":"2024-06-26T21:39:04.133669Z"},"trusted":true},"outputs":[],"source":["import nbimporter\n","from model import build_transformer, count_parameters # type: ignore\n","from config import get_config, get_weights_file_path, latest_weights_file_path"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:04.156631Z","iopub.status.busy":"2024-06-26T21:39:04.156295Z","iopub.status.idle":"2024-06-26T21:39:04.200646Z","shell.execute_reply":"2024-06-26T21:39:04.199632Z","shell.execute_reply.started":"2024-06-26T21:39:04.156604Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using Device: cpu\n"]}],"source":["# Define the Device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"Using Device:\", device)"]},{"cell_type":"markdown","metadata":{},"source":["# Tokenizer"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:04.203628Z","iopub.status.busy":"2024-06-26T21:39:04.203259Z","iopub.status.idle":"2024-06-26T21:39:04.213985Z","shell.execute_reply":"2024-06-26T21:39:04.213072Z","shell.execute_reply.started":"2024-06-26T21:39:04.203602Z"},"trusted":true},"outputs":[],"source":["def get_all_sentences(ds, lang):\n","    \"\"\"Generates the sentence\"\"\"\n","    for item in ds:\n","        yield item['translation'][lang]"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:04.215455Z","iopub.status.busy":"2024-06-26T21:39:04.215145Z","iopub.status.idle":"2024-06-26T21:39:04.226414Z","shell.execute_reply":"2024-06-26T21:39:04.225577Z","shell.execute_reply.started":"2024-06-26T21:39:04.215430Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["test_get_all_sentences: test success\n"]}],"source":["# Example\n","def test_get_all_sentences():\n","    input_dataset = [\n","        {'id': 1, 'translation': {'en': 'Hello', 'fr': 'Bonjour'}},\n","        {'id': 2, 'translation': {'en': 'Goodbye', 'fr': 'Au revoir'}}\n","    ]    \n","    expected_output = ['Bonjour', 'Au revoir'] \n","\n","    result_output = []\n","\n","    lang = 'fr'\n","    for sentence in get_all_sentences(input_dataset, lang):\n","        result_output.append(sentence)\n","    \n","    assert expected_output == result_output \n","    print(\"test_get_all_sentences: test success\")\n","    \n","test_get_all_sentences()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:04.227811Z","iopub.status.busy":"2024-06-26T21:39:04.227514Z","iopub.status.idle":"2024-06-26T21:39:04.238477Z","shell.execute_reply":"2024-06-26T21:39:04.237556Z","shell.execute_reply.started":"2024-06-26T21:39:04.227787Z"},"trusted":true},"outputs":[],"source":["def get_or_build_tokenizer(config, ds, lang):\n","    tokenizer_path = Path(config['tokenizer_file'].format(lang))\n","    if not Path.exists(tokenizer_path):\n","        print(f\"{tokenizer_path} does not exists.\")\n","        tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n","        tokenizer.pre_tokenizer = Whitespace()\n","        trainer = WordLevelTrainer(special_tokens = [\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"])\n","        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer=trainer)\n","        tokenizer.save(str(tokenizer_path))\n","    else:\n","        print(f\"{tokenizer_path} exists.\")\n","        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n","    return tokenizer\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:04.239695Z","iopub.status.busy":"2024-06-26T21:39:04.239426Z","iopub.status.idle":"2024-06-26T21:39:04.276038Z","shell.execute_reply":"2024-06-26T21:39:04.275118Z","shell.execute_reply.started":"2024-06-26T21:39:04.239672Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tokenizer_fr.json exists.\n","tokenizer_fr.json exists.\n","test_get_or_build_tokenizer: test success\n"]}],"source":["# Example\n","def test_get_or_build_tokenizer():\n","\n","    config = {\n","        'tokenizer_file': 'tokenizer_{0}.json'\n","    }\n","\n","    dataset = [\n","        {'id': 1, 'translation': {'en': 'Hello world', 'fr': 'Bonjour tout le monde'}},\n","        {'id': 2, 'translation': {'en': 'How are you?', 'fr': 'Comment ça va ?'}}\n","    ]\n","\n","    lang = 'fr'\n","    tokenizer_not_exist = get_or_build_tokenizer(config, dataset, lang)\n","    tokenizer = get_or_build_tokenizer(config, dataset, lang)\n","    \n","    assert tokenizer.encode(\"Bonjour tout le monde yash\").tokens == ['Bonjour', 'tout', 'le', 'monde', '[UNK]']\n","    assert tokenizer.encode(\"Bonjour tout le monde yash\").ids == [5, 9, 7, 8, 0]\n","    \n","    print(\"test_get_or_build_tokenizer: test success\")\n","    \n","test_get_or_build_tokenizer()"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:04.279425Z","iopub.status.busy":"2024-06-26T21:39:04.279123Z","iopub.status.idle":"2024-06-26T21:39:04.294447Z","shell.execute_reply":"2024-06-26T21:39:04.293471Z","shell.execute_reply.started":"2024-06-26T21:39:04.279398Z"},"trusted":true},"outputs":[],"source":["class BilingualDataset(Dataset):\n","    def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len) -> None:\n","        super().__init__()\n","        self.ds = ds\n","        self.tokenizer_src = tokenizer_src\n","        self.tokenizer_tgt = tokenizer_tgt\n","        self.src_lang = src_lang\n","        self.tgt_lang = tgt_lang\n","        self.seq_len = seq_len\n","\n","        # since all these token for both lang remain same we can use tokenizer_tgt or tokenizer_src\n","        self.sos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[SOS]\")], dtype=torch.int64)\n","        self.eos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[EOS]\")], dtype=torch.int64)\n","        self.pad_token = torch.tensor([tokenizer_tgt.token_to_id(\"[PAD]\")], dtype=torch.int64)\n","\n","    @staticmethod\n","    def causal_mask(size):\n","        mask = torch.triu(torch.ones(1, size, size), diagonal=1).type(torch.int) # create right upper diagonal matrix\n","        return mask == 0\n","\n","    def __len__(self):\n","        return len(self.ds)\n","    \n","    def __getitem__(self, index):\n","        src_target_pair = self.ds[index]\n","        src_text = src_target_pair['translation'][self.src_lang]\n","        tgt_text = src_target_pair['translation'][self.tgt_lang]\n","        \n","        enc_input_tokens = self.tokenizer_src.encode(src_text).ids\n","        dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n","\n","        enc_num_padding_tokens = self.seq_len - len(enc_input_tokens) - 2 # SOS and EOS\n","        dec_num_padding_tokens = self.seq_len - len(dec_input_tokens) - 1 # no EOS or SOS\n","\n","        if enc_num_padding_tokens < 0:\n","            raise ValueError('Sentence is too long')\n","        \n","        # add SOS and EOS to the source text\n","        encoder_input = torch.cat(\n","            [\n","                self.sos_token,\n","                torch.tensor(enc_input_tokens, dtype = torch.int64),\n","                self.eos_token,\n","                torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype = torch.int64)\n","            ]   \n","        )\n","\n","        decoder_input = torch.cat(\n","            [\n","                self.sos_token,\n","                torch.tensor(dec_input_tokens, dtype = torch.int64),\n","                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype = torch.int64)\n","            ]   \n","        )\n","\n","        label = torch.cat(\n","            [\n","                torch.tensor(dec_input_tokens, dtype = torch.int64),\n","                self.eos_token,\n","                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype = torch.int64)\n","            ]   \n","        )\n","\n","        return {\n","            \"encoder_input\": encoder_input, #seq_len\n","            \"decoder_input\": decoder_input, #seq_len\n","            \"encoder_mask\": (encoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int(), # (1, 1, seq_len)\n","            \"decoder_mask\": (decoder_input != self.pad_token).unsqueeze(0).int() & BilingualDataset.causal_mask(decoder_input.size(0)), # (1,seq_len) & (1, seq_len, seq_len)\n","            \"label\": label,\n","            \"src_text\": src_text,\n","            \"tgt_text\": tgt_text\n","        }"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:04.295966Z","iopub.status.busy":"2024-06-26T21:39:04.295675Z","iopub.status.idle":"2024-06-26T21:39:04.375943Z","shell.execute_reply":"2024-06-26T21:39:04.374995Z","shell.execute_reply.started":"2024-06-26T21:39:04.295941Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tokenizer_en_test.json exists.\n","tokenizer_fr_test.json exists.\n","Encoder Input: torch.Size([1, 10])\n","Decoder Input: torch.Size([1, 10])\n","Encoder Mask: torch.Size([1, 1, 1, 10])\n","Decoder Mask: torch.Size([1, 1, 10, 10])\n","Label: torch.Size([1, 10])\n","Source Text: ['How are you?']\n","Target Text: ['Comment ça va ?']\n","---\n","Encoder Input: torch.Size([1, 10])\n","Decoder Input: torch.Size([1, 10])\n","Encoder Mask: torch.Size([1, 1, 1, 10])\n","Decoder Mask: torch.Size([1, 1, 10, 10])\n","Label: torch.Size([1, 10])\n","Source Text: ['Hello world']\n","Target Text: ['Bonjour tout le monde']\n","---\n"]}],"source":["# Example \n","def test_BilingualDataset():\n","    dataset = [\n","        {'id': 1, 'translation': {'en_test': 'Hello world', 'fr_test': 'Bonjour tout le monde'}},\n","        {'id': 2, 'translation': {'en_test': 'How are you?', 'fr_test': 'Comment ça va ?'}}\n","    ]\n","\n","    # Example config\n","    config = {\n","        'tokenizer_file': 'tokenizer_{0}.json'\n","    }\n","\n","    tokenizer_src = get_or_build_tokenizer(config, dataset, \"en_test\")\n","    tokenizer_tgt = get_or_build_tokenizer(config, dataset, \"fr_test\")\n","\n","    # Example usage\n","    lang = 'fr_test'\n","    bilingual_dataset = BilingualDataset(dataset, tokenizer_src, tokenizer_tgt, 'en_test', lang, 10)\n","\n","    # Create a DataLoader for batching the data\n","    dataloader = DataLoader(bilingual_dataset, batch_size=1, shuffle=True)\n","    \n","    batch_num = 0\n","    # Iterate over the DataLoader to print batches\n","    for batch in dataloader:\n","        print(\"Encoder Input:\", batch[\"encoder_input\"].shape)\n","        print(\"Decoder Input:\", batch[\"decoder_input\"].shape)\n","        print(\"Encoder Mask:\", batch[\"encoder_mask\"].shape)\n","        print(\"Decoder Mask:\", batch[\"decoder_mask\"].shape)\n","        print(\"Label:\", batch[\"label\"].shape)\n","        print(\"Source Text:\", batch[\"src_text\"])\n","        print(\"Target Text:\", batch[\"tgt_text\"])\n","        print(\"---\")\n","        batch_num += 1\n","    \n","    assert batch_num == len(dataset)//dataloader.batch_size\n","    \n","test_BilingualDataset()"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:04.377739Z","iopub.status.busy":"2024-06-26T21:39:04.377399Z","iopub.status.idle":"2024-06-26T21:39:04.387775Z","shell.execute_reply":"2024-06-26T21:39:04.386647Z","shell.execute_reply.started":"2024-06-26T21:39:04.377712Z"},"trusted":true},"outputs":[],"source":["def get_ds(config):\n","    ds_raw = load_dataset('opus_books', f'{config[\"lang_src\"]}-{config[\"lang_tgt\"]}', split='train')\n","    # build tokenizers\n","    tokenizer_src = get_or_build_tokenizer(config, ds_raw, config['lang_src'])\n","    tokenizer_tgt = get_or_build_tokenizer(config, ds_raw, config['lang_tgt'])\n","    # keep 90% for training and 10% for validation\n","    train_ds_size = int(0.9 * len(ds_raw))\n","    val_ds_size = len(ds_raw) - train_ds_size\n","    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size])\n","\n","    train_ds = BilingualDataset(\n","        train_ds_raw, \n","        tokenizer_src, \n","        tokenizer_tgt, \n","        config['lang_src'], \n","        config['lang_tgt'], \n","        config['seq_len']\n","    )\n","    val_ds = BilingualDataset(\n","        val_ds_raw, \n","        tokenizer_src, \n","        tokenizer_tgt, \n","        config['lang_src'], \n","        config['lang_tgt'], \n","        config['seq_len']\n","    )\n","\n","    max_len_src = 0\n","    max_len_tgt = 0\n","    \n","    for item in ds_raw:\n","        src_ids = tokenizer_src.encode(item['translation'][config['lang_src']]).ids\n","        tgt_ids = tokenizer_tgt.encode(item['translation'][config['lang_src']]).ids\n","        \n","        max_len_src = max(max_len_src, len(src_ids))\n","        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n","\n","    print(f\"Max length for source senstences: {max_len_src}\")\n","    print(f\"Max length for target senstences: {max_len_tgt}\")\n","\n","    train_dataloader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n","    val_dataloader = DataLoader(val_ds, batch_size=1, shuffle=False)\n","\n","    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt\n","    "]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:04.389211Z","iopub.status.busy":"2024-06-26T21:39:04.388935Z","iopub.status.idle":"2024-06-26T21:39:16.732618Z","shell.execute_reply":"2024-06-26T21:39:16.731655Z","shell.execute_reply.started":"2024-06-26T21:39:04.389187Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"20f1036189d64ec8a2690ef380b9a486","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/28.1k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55225ad68c904a8abd8e66e980da7656","version_major":2,"version_minor":0},"text/plain":["train-00000-of-00001.parquet:   0%|          | 0.00/5.73M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"acc76646a2124ea59cd58caccd5f996b","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/32332 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tokenizer_en.json does not exists.\n","tokenizer_it.json does not exists.\n","Max length for source senstences: 309\n","Max length for target senstences: 309\n","Train Dataset Size: 29098\n","Validation Dataset Size: 3234\n","Source Language Tokenizer Vocabulary Size: 25138\n","Target Language Tokenizer Vocabulary Size: 30000\n","Encoder Input Shape: torch.Size([32, 500])\n","Decoder Input Shape: torch.Size([32, 500])\n","Encoder Mask Shape: torch.Size([32, 1, 1, 500])\n","Decoder Mask Shape: torch.Size([32, 1, 500, 500])\n","Label Shape: torch.Size([32, 500])\n","---\n"]}],"source":["def test_get_ds():\n","    config = {\n","        'lang_src': 'en',\n","        'lang_tgt': 'it',\n","        'seq_len': 500,\n","        'batch_size': 32,\n","        'tokenizer_file': 'tokenizer_{0}.json'\n","    }\n","\n","    train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n","\n","    # Print some information about the datasets and tokenizers\n","    print(f\"Train Dataset Size: {len(train_dataloader.dataset)}\")\n","    print(f\"Validation Dataset Size: {len(val_dataloader.dataset)}\")\n","    print(f\"Source Language Tokenizer Vocabulary Size: {len(tokenizer_src.get_vocab())}\")\n","    print(f\"Target Language Tokenizer Vocabulary Size: {len(tokenizer_tgt.get_vocab())}\")\n","\n","    # Iterate over a few batches from the dataloaders to check the data\n","    for batch in train_dataloader:\n","        print(\"Encoder Input Shape:\", batch[\"encoder_input\"].shape)\n","        print(\"Decoder Input Shape:\", batch[\"decoder_input\"].shape)\n","        print(\"Encoder Mask Shape:\", batch[\"encoder_mask\"].shape)\n","        print(\"Decoder Mask Shape:\", batch[\"decoder_mask\"].shape)\n","        print(\"Label Shape:\", batch[\"label\"].shape)\n","        print(\"---\")\n","        break  # Stop after printing the first batch\n","        \n","    assert len(tokenizer_src.get_vocab()) > 1000 and len(tokenizer_tgt.get_vocab()) > 1000\n","        \n","test_get_ds()   "]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:16.734158Z","iopub.status.busy":"2024-06-26T21:39:16.733865Z","iopub.status.idle":"2024-06-26T21:39:16.739194Z","shell.execute_reply":"2024-06-26T21:39:16.738058Z","shell.execute_reply.started":"2024-06-26T21:39:16.734132Z"},"trusted":true},"outputs":[],"source":["def get_model(config, vocab_src_len, vocab_tgt_len):\n","    model = build_transformer(vocab_src_len, vocab_tgt_len, config['seq_len'], config['seq_len'], config['d_model'])\n","    return model"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:16.742825Z","iopub.status.busy":"2024-06-26T21:39:16.742535Z","iopub.status.idle":"2024-06-26T21:39:17.617804Z","shell.execute_reply":"2024-06-26T21:39:17.616857Z","shell.execute_reply.started":"2024-06-26T21:39:16.742799Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["model.ipynb:50: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n","  ]\n"]}],"source":["def test_get_model():\n","    config  = {\n","        'seq_len': 500,\n","        'd_model': 512,\n","    }\n","    vocab_src_len = 512\n","    vocab_tgt_len = 512\n","\n","    model = get_model(config, vocab_src_len, vocab_tgt_len)\n","    model\n","    \n","test_get_model()"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:17.619988Z","iopub.status.busy":"2024-06-26T21:39:17.619193Z","iopub.status.idle":"2024-06-26T21:39:17.630600Z","shell.execute_reply":"2024-06-26T21:39:17.629710Z","shell.execute_reply.started":"2024-06-26T21:39:17.619953Z"},"trusted":true},"outputs":[],"source":["def causal_mask(size):\n","    mask = torch.triu(torch.ones(1, size, size), diagonal=1).type(torch.int)\n","    return mask == 0\n","\n","def greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len):\n","    \"\"\"\n","    Performs greedy decoding for sequence generation.\n","\n","    Args:\n","        model: The sequence-to-sequence model to use for decoding.\n","        source: The input sequence to encode.\n","        source_mask: The mask for the source sequence.\n","        tokenizer_src: The tokenizer for the source language.\n","        tokenizer_tgt: The tokenizer for the target language.\n","        max_len: The maximum length for the generated sequence.\n","        device: The device to perform the computations on.\n","\n","    Returns:\n","        torch.Tensor: The generated sequence.\n","    \"\"\"\n","    # Get the special tokens' IDs\n","    sos_idx = tokenizer_tgt.token_to_id(\"[SOS]\")\n","    eos_idx = tokenizer_tgt.token_to_id(\"[EOS]\")\n","\n","    # Encode the source sequence\n","    encoder_output = model.encode(source, source_mask)\n","\n","    # Initialize the decoder input with the start-of-sequence token\n","    decoder_input = torch.tensor([[sos_idx]], dtype=source_mask.dtype, device=device)\n","\n","    while True:\n","        # Check if the maximum length is reached\n","        if decoder_input.size(1) >= max_len:\n","            break\n","\n","        # Create a causal mask for the decoder input\n","        decoder_mask = causal_mask(decoder_input.size(1)).type_as(source_mask).to(device)\n","\n","        # Decode the current sequence\n","        decoder_output = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n","\n","        # Project the decoder output to the vocabulary size and get the next token\n","        logits = model.project(decoder_output[:, -1])\n","        next_word = torch.argmax(logits, dim=1).item()\n","\n","        # Append the next token to the decoder input\n","        next_word_tensor = torch.tensor([[next_word]], dtype=source.dtype, device=device)\n","        decoder_input = torch.cat([decoder_input, next_word_tensor], dim=1)\n","\n","        # Stop if the end-of-sequence token is generated\n","        if next_word == eos_idx:\n","            break\n","\n","    return decoder_input.squeeze(0)\n"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:17.632057Z","iopub.status.busy":"2024-06-26T21:39:17.631760Z","iopub.status.idle":"2024-06-26T21:39:17.865285Z","shell.execute_reply":"2024-06-26T21:39:17.864254Z","shell.execute_reply.started":"2024-06-26T21:39:17.632030Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tokenizer_en.json exists.\n","tokenizer_it.json exists.\n","Input Text: Hello, how are you?\n","Output Text: diportai ravvisassi coprissero cagin disseminate Passammo signora situati contrariamente bacchetta involto tintinnio mormorando chiudevano affermando portico generato Potemmo abbastanza\n"]}],"source":["# Example to test greedy_decode\n","class DummySeq2SeqModel:\n","    def encode(self, source, source_mask):\n","        # Fake encoding, in practice use your actual model\n","        return torch.randn(1, source.size(1), 768)\n","    \n","    def decode(self, encoder_output, source_mask, decoder_input, decoder_mask):\n","        # Fake decoding, in practice use your actual model\n","        return torch.randn(1, decoder_input.size(1), 768)\n","    \n","    def project(self, decoder_output):\n","        # Fake projection, in practice use your actual model\n","        vocab_size = 30522  # Assume BERT tokenizer vocab size\n","        return torch.randn(decoder_output.size(0), vocab_size)\n","\n","config = get_config()\n","\n","# Load pre-trained tokenizers\n","tokenizer_src = get_or_build_tokenizer(config, None, config['lang_src'])\n","tokenizer_tgt = get_or_build_tokenizer(config, None, config['lang_tgt'])\n","    \n","# Example input sequence\n","source_text = \"Hello, how are you?\"\n","source = torch.tensor(tokenizer_src.encode(source_text).ids).unsqueeze(0)\n","\n","source_mask = torch.ones_like(source).to(device)\n","\n","# Instantiate the dummy model\n","model = DummySeq2SeqModel()\n","\n","# Define other parameters\n","max_len = 20\n","\n","# Perform greedy decoding\n","output_sequence = greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len)\n","\n","# Convert the output sequence to text\n","output_text = tokenizer_tgt.decode(output_sequence.tolist())\n","# tokenizer_tgt.\n","# Print the result\n","print(\"Input Text:\", source_text)\n","print(\"Output Text:\", output_text)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:17.866956Z","iopub.status.busy":"2024-06-26T21:39:17.866661Z","iopub.status.idle":"2024-06-26T21:39:17.876405Z","shell.execute_reply":"2024-06-26T21:39:17.875517Z","shell.execute_reply.started":"2024-06-26T21:39:17.866929Z"},"trusted":true},"outputs":[],"source":["def bleu_loss(model, validation_ds, tokenizer_src, tokenizer_tgt, num_examples=2, max_len=20):\n","    \"\"\"\n","    Computes validation loss using a given model and dataset, and calculates BLEU score.\n","\n","    Args:\n","        model (torch.nn.Module): The trained model to evaluate.\n","        validation_ds (torch.utils.data.Dataset): Dataset for validation.\n","        tokenizer_src (Tokenizer): Tokenizer for source language.\n","        tokenizer_tgt (Tokenizer): Tokenizer for target language.\n","        num_examples (int, optional): Number of examples to evaluate. Defaults to 2.\n","        max_len (int, optional): Maximum length for decoding. Defaults to 50.\n","        device (str, optional): Device for tensor computations ('cuda' or 'cpu'). Defaults to 'cuda'.\n","\n","    Returns:\n","        float: BLEU score for the predicted outputs compared to expected outputs.\n","    \"\"\"\n","    try:\n","        model.eval()  # Set model to evaluation mode\n","    except:\n","        pass\n","        \n","    source_texts = []\n","    expected = []\n","    predicted = []\n","\n","    with torch.no_grad():\n","        for count, batch in enumerate(validation_ds):\n","            if count == num_examples:\n","                break\n","\n","            encoder_input = batch[\"encoder_input\"].to(device)\n","            encoder_mask = batch[\"encoder_mask\"].to(device)\n","\n","            assert encoder_input.size(0) == 1, \"Batch size must be 1 for validation\"\n","\n","            # Generate predictions using greedy decoding\n","            model_out = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len)\n","\n","            source_text = batch[\"src_text\"][0]\n","            target_text = batch[\"tgt_text\"][0]\n","            model_out_text = tokenizer_tgt.decode(model_out.tolist())\n","\n","            source_texts.append(source_text)\n","            expected.append(target_text)\n","            predicted.append(model_out_text)\n","\n","    # Compute the BLEU metric\n","    metric = BLEUScore()\n","    bleu = metric(predicted, expected)\n","\n","#     print(source_texts, expected, predicted)\n","    \n","    return bleu\n"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:17.877872Z","iopub.status.busy":"2024-06-26T21:39:17.877576Z","iopub.status.idle":"2024-06-26T21:39:24.483312Z","shell.execute_reply":"2024-06-26T21:39:24.482386Z","shell.execute_reply.started":"2024-06-26T21:39:17.877846Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tokenizer_en.json exists.\n","tokenizer_it.json exists.\n","Max length for source senstences: 309\n","Max length for target senstences: 309\n","BLEUScore: 0.0\n"]}],"source":["# Example to test greedy_decode\n","class DummySeq2SeqModel:\n","    def encode(self, source, source_mask):\n","        # Fake encoding, in practice use your actual model\n","        return torch.randn(1, source.size(1), 768)\n","    \n","    def decode(self, encoder_output, source_mask, decoder_input, decoder_mask):\n","        # Fake decoding, in practice use your actual model\n","        return torch.randn(1, decoder_input.size(1), 768)\n","    \n","    def project(self, decoder_output):\n","        # Fake projection, in practice use your actual model\n","        vocab_size = 30522  # Assume BERT tokenizer vocab size\n","        return torch.randn(decoder_output.size(0), vocab_size)\n","\n","config = get_config()\n","\n","train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n","\n","# Instantiate the dummy model\n","model = DummySeq2SeqModel()\n","\n","# Define other parameters\n","max_len = 20\n","\n","# Perform greedy decoding\n","loss = bleu_loss(model, val_dataloader, tokenizer_src, tokenizer_tgt, num_examples=2, max_len=5)\n","\n","print(\"BLEUScore:\", float(loss))"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:24.484964Z","iopub.status.busy":"2024-06-26T21:39:24.484657Z","iopub.status.idle":"2024-06-26T21:39:24.501120Z","shell.execute_reply":"2024-06-26T21:39:24.500214Z","shell.execute_reply.started":"2024-06-26T21:39:24.484936Z"},"trusted":true},"outputs":[],"source":["def custom_trainer(config):\n","\n","    # Make sure the weights folder exists\n","    Path(f\"{config['datasource']}_{config['model_folder']}\").mkdir(parents=True, exist_ok=True)\n","\n","    train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n","\n","    model = get_model(\n","        config, \n","        tokenizer_src.get_vocab_size(), \n","        tokenizer_tgt.get_vocab_size()\n","    ).to(device)\n","    \n","    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], eps=1e-9)\n","\n","    # If the user specified a model to preload before training, load it\n","    initial_epoch = 0\n","    global_step = 0\n","    preload = config['preload']\n","    model_filename = latest_weights_file_path(config) if preload == 'latest' else get_weights_file_path(config, preload) if preload else None\n","\n","    if model_filename:\n","        print(f\"Preloading model: {model_filename}\")\n","        state = torch.load(model_filename)\n","        model.load_state_dict(state['model_state_dict'])\n","        initial_epoch = state['epoch'] + 1\n","        optimizer.load_state_dict(state['optimizer_state_dict'])\n","        global_step = state['global_step']\n","    else:\n","        print('No model to preload, starting from scratch')\n","\n","    loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_src.token_to_id('[PAD]'), label_smoothing=0.1).to(device)    \n","        \n","    # Example tensors\n","    # logits = torch.tensor([[2.0, 0.5, -0.5], [0.1, 1.0, -1.0], [0.2, 0.3, 0.8]], dtype=torch.float32)\n","    # targets = torch.tensor([0, 1, 2], dtype=torch.int64)\n","    # loss = loss_fn(logits, targets)\n","    \n","    for epoch in range(initial_epoch, config['num_epochs']):\n","\n","        torch.cuda.empty_cache()\n","        batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n","\n","        for i, batch in tqdm(enumerate(batch_iterator)):\n","                \n","            model.train()\n","            encoder_input = batch['encoder_input'].to(device) # (b, seq_len)\n","            decoder_input = batch['decoder_input'].to(device) # (B, seq_len)\n","            encoder_mask = batch['encoder_mask'].to(device) # (B, 1, 1, seq_len)\n","            decoder_mask = batch['decoder_mask'].to(device) # (B, 1, seq_len, seq_len)\n","\n","            # Run the tensors through the encoder, decoder and the projection layer\n","            encoder_output = model.encode(encoder_input, encoder_mask) # (B, seq_len, d_model)\n","            decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask) # (B, seq_len, d_model)\n","            proj_output = model.project(decoder_output) # (B, seq_len, vocab_size)\n","\n","            # Compare the output with the label\n","            label = batch['label'].to(device) # (B, seq_len)\n","\n","            # Compute the loss using a simple cross entropy\n","            loss = loss_fn(proj_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n","            \n","\n","            # Backpropagate the loss\n","            loss.backward()\n","\n","            # Update the weights\n","            optimizer.step()\n","            optimizer.zero_grad(set_to_none=True)\n","            print('h')\n","#             train_bleu_loss = bleu_loss(model, train_dataloader, tokenizer_src, tokenizer_tgt, num_examples=100, max_len=config['seq_len'])\n","            val_bleu_loss = bleu_loss(model, val_dataloader, tokenizer_src, tokenizer_tgt, num_examples=100, max_len=config['seq_len'])\n","            print('2')\n","            # Log the loss\n","            print(f'epoch_{epoch}__global_step_{global_step}__batch_no_{i}__train Cross Entropy loss_{loss.item()}__train BLEUloss_{float(val_bleu_loss)}__val BLEUloss_{float(val_bleu_loss)}')\n","\n","            global_step += 1\n","\n","        # Save the model at the end of every epoch\n","        model_filename = get_weights_file_path(config, f\"{epoch:02d}\")\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'global_step': global_step\n","        }, model_filename)\n"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T21:39:24.503077Z","iopub.status.busy":"2024-06-26T21:39:24.502416Z","iopub.status.idle":"2024-06-26T21:39:35.747028Z","shell.execute_reply":"2024-06-26T21:39:35.745623Z","shell.execute_reply.started":"2024-06-26T21:39:24.503038Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tokenizer_en.json exists.\n","tokenizer_it.json exists.\n","Max length for source senstences: 309\n","Max length for target senstences: 309\n","No model to preload, starting from scratch\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af6cd6e3b2fc45d0855c8dc8e55b8196","version_major":2,"version_minor":0},"text/plain":["Processing Epoch 00:   0%|          | 0/4850 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"195f46811af348a9a8b0ef0761249e7c","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"IndexError","evalue":"index out of range in self","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcustom_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[31], line 54\u001b[0m, in \u001b[0;36mcustom_trainer\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Run the tensors through the encoder, decoder and the projection layer\u001b[39;00m\n\u001b[1;32m     53\u001b[0m encoder_output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(encoder_input, encoder_mask) \u001b[38;5;66;03m# (B, seq_len, d_model)\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_mask\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B, seq_len, d_model)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m proj_output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mproject(decoder_output) \u001b[38;5;66;03m# (B, seq_len, vocab_size)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Compare the output with the label\u001b[39;00m\n","File \u001b[0;32m~/1898483/transformer_pytorch/experiments/model.ipynb:29\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, encoder_output, src_mask, tgt, tgt_mask)\u001b[0m\n\u001b[1;32m      1\u001b[0m {\n\u001b[1;32m      2\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcells\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      3\u001b[0m   {\n\u001b[1;32m      4\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m      6\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# **ATTENTION IS ALL YOU NEED!**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Language Translator\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReference: [Attention is all you need (Transformer) - Model explanation (including math), Inference and Training](https://www.youtube.com/@umarjamilai)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello Readers,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn this project, we are going to implement the transformer from the paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Project Overview\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis notebook will guide you through the following steps:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. **Data Preparation:** Loading and preprocessing the English-Italian translation dataset.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. **Model Architecture:** Building the transformer model as described in the paper.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3. **Training:** Training the transformer model on the dataset.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4. **Evaluation:** Evaluating the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms performance on test data.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5. **Inference:** Translating English sentences to Italian using the trained model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Workflow\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe will start with some helper functions, then usual imports, then directly jump into model architecture, then prepare the dataset for training, and finally perform inference. Variable names used in the code aligns with paper.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms get started!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m    ]\n\u001b[1;32m     37\u001b[0m   },\n\u001b[1;32m     38\u001b[0m   {\n\u001b[1;32m     39\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     41\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Model Architecture\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m    ]\n\u001b[1;32m     44\u001b[0m   },\n\u001b[1;32m     45\u001b[0m   {\n\u001b[1;32m     46\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     47\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     48\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/model_arch.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m300\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m    ]\n\u001b[1;32m     51\u001b[0m   },\n\u001b[1;32m     52\u001b[0m   {\n\u001b[1;32m     53\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     54\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     55\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#### Required imports\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m    ]\n\u001b[1;32m     58\u001b[0m   },\n\u001b[1;32m     59\u001b[0m   {\n\u001b[1;32m     60\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     61\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m6\u001b[39m,\n\u001b[1;32m     62\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     63\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     64\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch.nn as nn\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport math\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch.nn.functional as F\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m    ]\n\u001b[1;32m     70\u001b[0m   },\n\u001b[1;32m     71\u001b[0m   {\n\u001b[1;32m     72\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     73\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     74\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#### Helper Functions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m    ]\n\u001b[1;32m     77\u001b[0m   },\n\u001b[1;32m     78\u001b[0m   {\n\u001b[1;32m     79\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     80\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m7\u001b[39m,\n\u001b[1;32m     81\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     82\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     83\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef count_parameters(model):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Count and print the number of trainable parameters in a model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This function iterates over all parameters in the given model,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    filters those that require gradients (trainable parameters), \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    and prints each parameter\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms count. Finally, it prints the total\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    count of trainable parameters.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        model (torch.nn.Module): The model for which to count parameters.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Example:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        model = YourModel()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        count_parameters(model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    params = [p.numel() for p in model.parameters() if p.requires_grad]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for item in params:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        print(f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{item:>6}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m______\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124msum(params):>6}\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m    ]\n\u001b[1;32m    105\u001b[0m   },\n\u001b[1;32m    106\u001b[0m   {\n\u001b[1;32m    107\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    108\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    109\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Input Embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m    ]\n\u001b[1;32m    112\u001b[0m   },\n\u001b[1;32m    113\u001b[0m   {\n\u001b[1;32m    114\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    115\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    116\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/input_embedding.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m1000\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m    ]\n\u001b[1;32m    119\u001b[0m   },\n\u001b[1;32m    120\u001b[0m   {\n\u001b[1;32m    121\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    122\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m    123\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    124\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    125\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass InputEmbeddings(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Input Embeddings Class\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This class defines the input embedding layer used in the transformer model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    It converts input tokens to their corresponding embeddings and scales them\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    by the square root of the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms dimensionality (d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        d_model (int): The dimensionality of the embeddings.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        vocab_size (int): The size of the vocabulary (i.e., the number of unique tokens).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Methods:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        forward(x): Computes the embeddings for the input tokens and scales them.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, d_model: int, vocab_size: int):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.d_model = d_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.vocab_size = vocab_size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Define the embedding layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.embedding = nn.Embedding(vocab_size, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass for the input embeddings.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor containing token indices.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Scaled embeddings for the input tokens.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Compute embeddings and scale them by sqrt(d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.embedding(x) * math.sqrt(self.d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m    ]\n\u001b[1;32m    161\u001b[0m   },\n\u001b[1;32m    162\u001b[0m   {\n\u001b[1;32m    163\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    164\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m    165\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    166\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    167\u001b[0m     {\n\u001b[1;32m    168\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    169\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/plain\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    170\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Size([10, 50, 512])\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m       ]\n\u001b[1;32m    172\u001b[0m      },\n\u001b[1;32m    173\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m    174\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    175\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecute_result\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     }\n\u001b[1;32m    177\u001b[0m    ],\n\u001b[1;32m    178\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example usage\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 512  # Dimension of the model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_size = 25000  # Maximum length of the sequence\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_tensor = torch.randint(low = 0, high = vocab_size-1, size = (10,50), dtype=torch.int) # 10 lines, 50 words per line\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_embeddings = InputEmbeddings(d_model, vocab_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_embeddings(input_tensor).shape\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m    ]\n\u001b[1;32m    186\u001b[0m   },\n\u001b[1;32m    187\u001b[0m   {\n\u001b[1;32m    188\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    189\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m    190\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    191\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    192\u001b[0m     {\n\u001b[1;32m    193\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    194\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    195\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    196\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m12800000\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    197\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m______\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    198\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m12800000\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m      ]\n\u001b[1;32m    200\u001b[0m     }\n\u001b[1;32m    201\u001b[0m    ],\n\u001b[1;32m    202\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount_parameters(input_embeddings) # weights=> 512*25000\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m    ]\n\u001b[1;32m    205\u001b[0m   },\n\u001b[1;32m    206\u001b[0m   {\n\u001b[1;32m    207\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    208\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    209\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Positional Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m    ]\n\u001b[1;32m    212\u001b[0m   },\n\u001b[1;32m    213\u001b[0m   {\n\u001b[1;32m    214\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    215\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    216\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/Positional_encoding_1.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m1000\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/Positional_encoding_2.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m1000\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m    ]\n\u001b[1;32m    220\u001b[0m   },\n\u001b[1;32m    221\u001b[0m   {\n\u001b[1;32m    222\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m    224\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    225\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    226\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass PositionalEncoding(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Positional Encoding Class\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This class adds positional encoding to the input embeddings to provide \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    the model with information about the relative or absolute position of \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    tokens in the sequence. The implementation includes a dropout layer \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for regularization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        d_model (int): The dimensionality of the embeddings.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        seq_len (int): The maximum length of the input sequences.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        dropout (float): The dropout rate for regularization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        div_term_implementation (str): Specifies the method to compute the \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            division term. Options are \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodified\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Methods:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        forward(x): Adds positional encoding to the input tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, d_model: int, seq_len: int, dropout: float, div_term_implementation: str = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodified\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.d_model = d_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.seq_len = seq_len\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.dropout = nn.Dropout(dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Create a matrix of shape (seq_len, d_model) for positional encodings\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pe = torch.zeros(seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Create a vector of shape (seq_len, 1) for position indices\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Calculate the division term based on the specified implementation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if div_term_implementation == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            div_term = 1.0 / (10000 ** (torch.arange(0, d_model, 2).float() / d_model))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply sine to even indices and cosine to odd indices\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pe[:, 0::2] = torch.sin(position * div_term)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pe[:, 1::2] = torch.cos(position * div_term)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Add an extra dimension for batch size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pe = pe.unsqueeze(0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Register the positional encoding matrix as a buffer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.register_buffer(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, pe)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass for the positional encoding.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor containing embeddings.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Input tensor with added positional encoding.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Add positional encoding to the input tensor and disable gradient computation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = x + (self.pe[:, :x.shape[1],]).requires_grad_(False)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.dropout(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m    ]\n\u001b[1;32m    287\u001b[0m   },\n\u001b[1;32m    288\u001b[0m   {\n\u001b[1;32m    289\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    290\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m25\u001b[39m,\n\u001b[1;32m    291\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    292\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    293\u001b[0m     {\n\u001b[1;32m    294\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    295\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    296\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    297\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Size([32, 100, 512])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m      ]\n\u001b[1;32m    299\u001b[0m     }\n\u001b[1;32m    300\u001b[0m    ],\n\u001b[1;32m    301\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example usage\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 512  # Dimension of the model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_len = 5000  # Maximum length of the sequence\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos_encoder = PositionalEncoding(d_model, max_len, dropout=0.2)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Dummy input tensor with shape (batch size, sequence length, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.zeros(32, 100, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Apply positional encoding\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = pos_encoder(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(x.shape)  # Should output: torch.Size([100, 32, 512])\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m    ]\n\u001b[1;32m    314\u001b[0m   },\n\u001b[1;32m    315\u001b[0m   {\n\u001b[1;32m    316\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    317\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m27\u001b[39m,\n\u001b[1;32m    318\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    319\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    320\u001b[0m     {\n\u001b[1;32m    321\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    322\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    323\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    324\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m______\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    325\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m     0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m      ]\n\u001b[1;32m    327\u001b[0m     }\n\u001b[1;32m    328\u001b[0m    ],\n\u001b[1;32m    329\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount_parameters(pos_encoder)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m    ]\n\u001b[1;32m    332\u001b[0m   },\n\u001b[1;32m    333\u001b[0m   {\n\u001b[1;32m    334\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    335\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    336\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Layer Normalization\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m    ]\n\u001b[1;32m    339\u001b[0m   },\n\u001b[1;32m    340\u001b[0m   {\n\u001b[1;32m    341\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    342\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    343\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/Layer_Normalization.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m1000\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    345\u001b[0m    ]\n\u001b[1;32m    346\u001b[0m   },\n\u001b[1;32m    347\u001b[0m   {\n\u001b[1;32m    348\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    349\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m29\u001b[39m,\n\u001b[1;32m    350\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    351\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    352\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass LayerNormalization(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Layer Normalization Class\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This class applies layer normalization to the input tensor of batch. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Layer normalization normalizes the inputs across the features \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    (i.e., the last dimension) to have mean zero and variance one. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    It also includes learnable parameters for scaling and bias.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        features (int): Number of features in a model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        eps (float): A small value to avoid division by zero during normalization. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                     Default is 10**-6.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Methods:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        forward(x): Applies layer normalization to the input tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, features: int, eps: float = 10**-6):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.eps = eps\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.alpha = nn.Parameter(torch.ones(features))        # Learnable scaling parameter\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.bias = nn.Parameter(torch.zeros(features))         # Learnable bias parameter\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass for the layer normalization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor to be normalized.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Normalized input tensor with learnable scaling and bias.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # x: (batch, seq_len, hidden_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        mean = x.mean(dim=-1, keepdim=True) # (batch, seq_len, 1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        std = x.std(dim=-1, keepdim=True) # (batch, seq_len, 1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply normalization, scaling, and bias\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.alpha * (x - mean) / (std + self.eps) + self.bias\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m    ]\n\u001b[1;32m    393\u001b[0m   },\n\u001b[1;32m    394\u001b[0m   {\n\u001b[1;32m    395\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    396\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m47\u001b[39m,\n\u001b[1;32m    397\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    398\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    399\u001b[0m     {\n\u001b[1;32m    400\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    401\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    402\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    403\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput Shape: torch.Size([16, 500, 512])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    404\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput Shape: torch.Size([16, 500, 512])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    405\u001b[0m      ]\n\u001b[1;32m    406\u001b[0m     }\n\u001b[1;32m    407\u001b[0m    ],\n\u001b[1;32m    408\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example usage\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch = 16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 500\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 512\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Input tensor of shape (batch_size, sequence_length, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.randn(batch, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Instantiate the LayerNormalization class\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_norm = LayerNormalization(d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Apply layer normalization\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = layer_norm(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mInput Shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, x.shape)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput Shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    422\u001b[0m    ]\n\u001b[1;32m    423\u001b[0m   },\n\u001b[1;32m    424\u001b[0m   {\n\u001b[1;32m    425\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    426\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m48\u001b[39m,\n\u001b[1;32m    427\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    428\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    429\u001b[0m     {\n\u001b[1;32m    430\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    431\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    432\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    433\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   512\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    434\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   512\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    435\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m______\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    436\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  1024\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m      ]\n\u001b[1;32m    438\u001b[0m     }\n\u001b[1;32m    439\u001b[0m    ],\n\u001b[1;32m    440\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount_parameters(layer_norm)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m    ]\n\u001b[1;32m    443\u001b[0m   },\n\u001b[1;32m    444\u001b[0m   {\n\u001b[1;32m    445\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    446\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    447\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Feed Forward Block\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m    ]\n\u001b[1;32m    450\u001b[0m   },\n\u001b[1;32m    451\u001b[0m   {\n\u001b[1;32m    452\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    453\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m49\u001b[39m,\n\u001b[1;32m    454\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    455\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    456\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass FeedForwardBlock(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    FeedForward Block Class\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This class defines a feedforward neural network block used in the \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    transformer model. It consists of two linear transformations with \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    a ReLU activation in between, and dropout for regularization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        d_model (int): The dimensionality of the input and output features.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        d_ff (int): The dimensionality of the intermediate (hidden) features.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        dropout (float): The dropout rate for regularization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Methods:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        forward(x): Applies the feedforward block to the input tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # First linear layer with input size d_model and output size d_ff\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.linear_1 = nn.Linear(d_model, d_ff) # W1 and B1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Dropout layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.dropout = nn.Dropout(dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Second linear layer with input size d_ff and output size d_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.linear_2 = nn.Linear(d_ff, d_model) # W2 and B2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass for the feedforward block.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor with shape (Batch, Seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Output tensor with shape (Batch, Seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply the first linear layer, ReLU activation, dropout, and then the second linear layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # (Batch, Seq_len, d_model) -> (Batch, Seq_len, d_ff) -> (Batch, Seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m    ]\n\u001b[1;32m    496\u001b[0m   },\n\u001b[1;32m    497\u001b[0m   {\n\u001b[1;32m    498\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    499\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m    500\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    501\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    502\u001b[0m     {\n\u001b[1;32m    503\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    504\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    505\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    506\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput Shape: torch.Size([16, 500, 512])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    507\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput Shape: torch.Size([16, 500, 512])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m      ]\n\u001b[1;32m    509\u001b[0m     }\n\u001b[1;32m    510\u001b[0m    ],\n\u001b[1;32m    511\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example usage\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size = 16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 500\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 512\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Input tensor of shape (batch_size, sequence_length, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.randn(batch_size, seq_len, d_model)  # Example input tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Instantiate the FeedForwardBlock class\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_ff = 2048  # Dimension of the feedforward layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout = 0.1  # Dropout rate\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Apply the feedforward block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = feed_forward_block(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mInput Shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, x.shape)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput Shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    529\u001b[0m    ]\n\u001b[1;32m    530\u001b[0m   },\n\u001b[1;32m    531\u001b[0m   {\n\u001b[1;32m    532\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    533\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m51\u001b[39m,\n\u001b[1;32m    534\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    535\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    536\u001b[0m     {\n\u001b[1;32m    537\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    538\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    539\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    540\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1048576\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    541\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  2048\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    542\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1048576\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    543\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   512\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    544\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m______\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    545\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2099712\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m      ]\n\u001b[1;32m    547\u001b[0m     }\n\u001b[1;32m    548\u001b[0m    ],\n\u001b[1;32m    549\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount_parameters(feed_forward_block)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m    ]\n\u001b[1;32m    552\u001b[0m   },\n\u001b[1;32m    553\u001b[0m   {\n\u001b[1;32m    554\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    555\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    556\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# 26th March 10:32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m    ]\n\u001b[1;32m    559\u001b[0m   },\n\u001b[1;32m    560\u001b[0m   {\n\u001b[1;32m    561\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    562\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    563\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Multi-Head Attention\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    565\u001b[0m    ]\n\u001b[1;32m    566\u001b[0m   },\n\u001b[1;32m    567\u001b[0m   {\n\u001b[1;32m    568\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    570\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/Multi_head_attention.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m1200\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m    ]\n\u001b[1;32m    573\u001b[0m   },\n\u001b[1;32m    574\u001b[0m   {\n\u001b[1;32m    575\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    576\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m54\u001b[39m,\n\u001b[1;32m    577\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    578\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    579\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MultiHeadAttentionBlock(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Multi-Head Attention Block Class\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This class implements the multi-head attention mechanism as described \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    in the \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mAttention Is All You Need\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m paper. It allows the model to jointly \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    attend to information from different representation subspaces.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        d_model (int): The dimensionality of the input and output features.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        h (int): The number of attention heads.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        dropout (float): The dropout rate for regularization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Methods:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        forward(q, k, v, mask): Applies multi-head attention to the input tensors.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, d_model: int, h: int, dropout: float):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.d_model = d_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.h = h\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        assert d_model\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mh == 0, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124md_model not divisible by h\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.d_k = d_model//h\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.w_q = nn.Linear(d_model, d_model) #wq\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.w_k = nn.Linear(d_model, d_model) #wk\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.w_v = nn.Linear(d_model, d_model) #wv\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.w_o = nn.Linear(d_model, d_model) #wo\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.dropout = nn.Dropout(dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @staticmethod \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def attention(query, key, value, mask, dropout: nn.Dropout):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Compute the attention scores and apply the attention mechanism.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            query (torch.Tensor): Query tensor of shape (Batch, h, Seq_Len, d_k).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            key (torch.Tensor): Key tensor of shape (Batch, h, Seq_Len, d_k).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            value (torch.Tensor): Value tensor of shape (Batch, h, Seq_Len, d_k).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            mask (torch.Tensor): Mask tensor to avoid attending to certain positions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            dropout (nn.Dropout): Dropout layer for regularization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: The output tensor after applying attention.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: The attention scores.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        d_k = query.shape[-1]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # (Batch, h, seq_len, d_k) -> (Batch, h, seq_len, seq_len)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if mask is not None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # very low value (indicateing -inf) to positions where mask == 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            attention_scores.masked_fill(mask==0,-1e9)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        attention_scores = attention_scores.softmax(dim = -1) # (Batch, h, seq_len, seq_len)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if dropout is not None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            attention_scores = dropout(attention_scores)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # (batch. h. seq_len, seq_len) -> (batch, h, seq_len, d_k)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # also resturn attention scores used for visualization\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return (attention_scores @ value), attention_scores        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, q, k, v, mask):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass for the multi-head attention block.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            q (torch.Tensor): Query tensor of shape (Batch, Seq_Len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            k (torch.Tensor): Key tensor of shape (Batch, Seq_Len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            v (torch.Tensor): Value tensor of shape (Batch, Seq_Len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            mask (torch.Tensor): Mask tensor to avoid attending to certain positions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: The output tensor after applying multi-head attention.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply linear layers to get query, key, and value tensors\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        query = self.w_q(q) # (Batch, Seq_Len, d_model) -> (Batch, Seq_Len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        key = self.w_k(k) # (Batch, Seq_Len, d_model) -> (Batch, Seq_Len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        value = self.w_v(v) # (Batch, Seq_Len, d_model) -> (Batch, Seq_Len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # (Batch, Seq_Len, d_model) -> (Batch, Seq_Len, h, d_k) -> (Batch, h, Seq_Len, d_k)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1,2)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1,2)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1,2)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply the attention mechanism\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x, self.attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Reshape and transpose back to the original shape\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # (Batch, h, seq_len, d_k) -> (Batch, seq_len, h, d_k) -> (Batch, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = x.transpose(1,2).contiguous().view(x.shape[0], -1, self.h*self.d_k)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply the final linear layer (Batch, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.w_o(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    679\u001b[0m    ]\n\u001b[1;32m    680\u001b[0m   },\n\u001b[1;32m    681\u001b[0m   {\n\u001b[1;32m    682\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    683\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m56\u001b[39m,\n\u001b[1;32m    684\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    685\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    686\u001b[0m     {\n\u001b[1;32m    687\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    688\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    689\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    690\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape: torch.Size([2, 5, 16])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    691\u001b[0m      ]\n\u001b[1;32m    692\u001b[0m     }\n\u001b[1;32m    693\u001b[0m    ],\n\u001b[1;32m    694\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size = 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 5\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh = 4\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout = 0.1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create a random tensor with shape (Batch, Seq_Len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq = torch.rand(batch_size, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk = torch.rand(batch_size, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv = torch.rand(batch_size, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create a mask tensor to avoid attending to certain positions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask = torch.ones(batch_size, 1, seq_len, seq_len)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask[:, :, 2:, :] = 0  # Masking out the last three positions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create a multi-head attention block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmha_block = MultiHeadAttentionBlock(d_model, h, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Apply the multi-head attention block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = mha_block(q, k, v, mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    716\u001b[0m    ]\n\u001b[1;32m    717\u001b[0m   },\n\u001b[1;32m    718\u001b[0m   {\n\u001b[1;32m    719\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    720\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m57\u001b[39m,\n\u001b[1;32m    721\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    722\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    723\u001b[0m     {\n\u001b[1;32m    724\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    725\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    726\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    727\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   256\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    728\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    729\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   256\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    730\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    731\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   256\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    732\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    733\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   256\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    734\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    735\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m______\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    736\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  1088\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    737\u001b[0m      ]\n\u001b[1;32m    738\u001b[0m     }\n\u001b[1;32m    739\u001b[0m    ],\n\u001b[1;32m    740\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount_parameters(mha_block)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    742\u001b[0m    ]\n\u001b[1;32m    743\u001b[0m   },\n\u001b[1;32m    744\u001b[0m   {\n\u001b[1;32m    745\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    746\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    747\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Residual Layer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    749\u001b[0m    ]\n\u001b[1;32m    750\u001b[0m   },\n\u001b[1;32m    751\u001b[0m   {\n\u001b[1;32m    752\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    753\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    754\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/Residual_network.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m300\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    756\u001b[0m    ]\n\u001b[1;32m    757\u001b[0m   },\n\u001b[1;32m    758\u001b[0m   {\n\u001b[1;32m    759\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    760\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m61\u001b[39m,\n\u001b[1;32m    761\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    762\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    763\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass ResidualConnection(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Residual Connection with Layer Normalization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This module adds a residual connection around any given sublayer \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    with layer normalization and dropout applied before the residual \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    connection is added.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        features (int): Number of input features\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        dropout (float): Dropout rate to be applied after the sublayer.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, features: int, dropout: float) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.dropout = nn.Dropout(dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.norm = LayerNormalization(features)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x, sublayer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Apply residual connection to any sublayer.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            sublayer (Callable): A sublayer function or module.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Output tensor after applying the residual connection and dropout.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Norm and Add\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return x + self.dropout(sublayer(self.norm(x)))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    794\u001b[0m    ]\n\u001b[1;32m    795\u001b[0m   },\n\u001b[1;32m    796\u001b[0m   {\n\u001b[1;32m    797\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    798\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m62\u001b[39m,\n\u001b[1;32m    799\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    800\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    801\u001b[0m     {\n\u001b[1;32m    802\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    803\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    804\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    805\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape: torch.Size([16, 500, 512])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    806\u001b[0m      ]\n\u001b[1;32m    807\u001b[0m     }\n\u001b[1;32m    808\u001b[0m    ],\n\u001b[1;32m    809\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example usage\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size = 16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 500\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 512\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout_rate = 0.1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create a random tensor with shape (Batch, Seq_Len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.rand(batch_size, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Define a simple sublayer function for demonstration\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass SimpleSublayer(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, d_model):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.linear = nn.Linear(d_model, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return F.relu(self.linear(x))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msublayer = SimpleSublayer(d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create a residual connection block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresidual_connection = ResidualConnection(d_model, dropout_rate)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Apply the residual connection block with the sublayer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = residual_connection(x, sublayer)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    837\u001b[0m    ]\n\u001b[1;32m    838\u001b[0m   },\n\u001b[1;32m    839\u001b[0m   {\n\u001b[1;32m    840\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    841\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m63\u001b[39m,\n\u001b[1;32m    842\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    843\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    844\u001b[0m     {\n\u001b[1;32m    845\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    846\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    847\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    848\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   512\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    849\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   512\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    850\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m______\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    851\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  1024\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    852\u001b[0m      ]\n\u001b[1;32m    853\u001b[0m     }\n\u001b[1;32m    854\u001b[0m    ],\n\u001b[1;32m    855\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount_parameters(residual_connection)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    857\u001b[0m    ]\n\u001b[1;32m    858\u001b[0m   },\n\u001b[1;32m    859\u001b[0m   {\n\u001b[1;32m    860\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    861\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    862\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Encoder Block\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    864\u001b[0m    ]\n\u001b[1;32m    865\u001b[0m   },\n\u001b[1;32m    866\u001b[0m   {\n\u001b[1;32m    867\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    868\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    869\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/Encoder.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m300\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m    ]\n\u001b[1;32m    872\u001b[0m   },\n\u001b[1;32m    873\u001b[0m   {\n\u001b[1;32m    874\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    875\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m    876\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    877\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    878\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass EncoderBlock(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, features: int, self_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Encoder Block for a Transformer model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        This block consists of a self-attention mechanism followed by a feed-forward network, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        with residual connections and layer normalization applied to each sublayer.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            features (int): Number of input Features\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self_attention_block (MultiHeadAttentionBlock): Multi-head self-attention mechanism.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            feed_forward_block (FeedForwardBlock): Feed-forward network.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            dropout (float): Dropout rate to be applied after each sublayer.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.self_attention_block = self_attention_block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.feed_forward_block = feed_forward_block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(2)])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x, src_mask):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass through the encoder block.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor of shape (batch_size, seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            src_mask (torch.Tensor): Source mask tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Output tensor after applying self-attention, feed-forward network, and residual connections.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply the first residual connection with the self-attention block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, src_mask))  # try without lambda\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply the second residual connection with the feed-forward block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = self.residual_connections[1](x, lambda x: self.feed_forward_block(x))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return x\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    916\u001b[0m    ]\n\u001b[1;32m    917\u001b[0m   },\n\u001b[1;32m    918\u001b[0m   {\n\u001b[1;32m    919\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    920\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m65\u001b[39m,\n\u001b[1;32m    921\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    922\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    923\u001b[0m     {\n\u001b[1;32m    924\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    925\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    926\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    927\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape: torch.Size([2, 5, 16])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    928\u001b[0m      ]\n\u001b[1;32m    929\u001b[0m     }\n\u001b[1;32m    930\u001b[0m    ],\n\u001b[1;32m    931\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size = 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 5\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh = 4\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_ff = 32\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout_rate = 0.1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create random tensors for input and mask\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.rand(batch_size, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    942\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create a mask tensor to avoid attending to certain positions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    943\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask = torch.ones(batch_size, 1, seq_len, seq_len)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask[:, :, 2:, :] = 0  # Masking out the last three positions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Initialize self-attention block and feed-forward block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself_attention_block = MultiHeadAttentionBlock(d_model, h, dropout_rate)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeed_forward_block = FeedForwardBlock(d_model, d_ff, dropout_rate)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Initialize the encoder block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    951\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_block = EncoderBlock(d_model, self_attention_block, feed_forward_block, dropout_rate)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Apply the encoder block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = encoder_block(x, mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    956\u001b[0m    ]\n\u001b[1;32m    957\u001b[0m   },\n\u001b[1;32m    958\u001b[0m   {\n\u001b[1;32m    959\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    960\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    961\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Encoder\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    963\u001b[0m    ]\n\u001b[1;32m    964\u001b[0m   },\n\u001b[1;32m    965\u001b[0m   {\n\u001b[1;32m    966\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    967\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m68\u001b[39m,\n\u001b[1;32m    968\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    969\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    970\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass Encoder(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Encoder block for a Transformer model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This block consists of a stack of layers (e.g., multi-head self-attention and feed-forward networks)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    followed by layer normalization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, features: int, layers: nn.ModuleList) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Initializes the Encoder with a list of layers and a layer normalization module.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            features (int): Number of input features\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            layers (nn.ModuleList): List of layers to be included in the encoder.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.layers = layers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.norm = LayerNormalization(features)  # Initialize layer normalization\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x, mask):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    992\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass through the encoder.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor of shape (batch_size, seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            mask (torch.Tensor): Mask tensor of shape (batch_size, 1, 1, seq_len).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Output tensor after applying all layers and layer normalization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1000\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1001\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for layer in self.layers:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x = layer(x, mask)  # Apply each layer in the list to the input\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.norm(x)  # Apply layer normalization to the final output\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1004\u001b[0m    ]\n\u001b[1;32m   1005\u001b[0m   },\n\u001b[1;32m   1006\u001b[0m   {\n\u001b[1;32m   1007\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1008\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m70\u001b[39m,\n\u001b[1;32m   1009\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1010\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1011\u001b[0m     {\n\u001b[1;32m   1012\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1013\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1014\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1015\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape: torch.Size([2, 5, 16])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1016\u001b[0m      ]\n\u001b[1;32m   1017\u001b[0m     }\n\u001b[1;32m   1018\u001b[0m    ],\n\u001b[1;32m   1019\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size = 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 5\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh = 4\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_ff = 32\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout_rate = 0.1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1028\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create random tensors for input and mask\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.rand(batch_size, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create a mask tensor to avoid attending to certain positions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask = torch.ones(batch_size, 1, seq_len, seq_len)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask[:, :, 2:, :] = 0  # Masking out the last three positions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Initialize self-attention block and feed-forward block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself_attention_block = MultiHeadAttentionBlock(d_model, h, dropout_rate)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeed_forward_block = FeedForwardBlock(d_model, d_ff, dropout_rate)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Initialize the encoder block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_blocks = nn.ModuleList()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor i in range(10):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    encoder_blocks.append(EncoderBlock(d_model, self_attention_block, feed_forward_block, dropout_rate))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder = Encoder(d_model, encoder_blocks)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Apply the encoder block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = encoder(x, mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m    ]\n\u001b[1;32m   1049\u001b[0m   },\n\u001b[1;32m   1050\u001b[0m   {\n\u001b[1;32m   1051\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1052\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[1;32m   1053\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1054\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m   1055\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m # count_parameters(encoder)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1057\u001b[0m    ]\n\u001b[1;32m   1058\u001b[0m   },\n\u001b[1;32m   1059\u001b[0m   {\n\u001b[1;32m   1060\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1061\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1062\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Decoder_Block\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1064\u001b[0m    ]\n\u001b[1;32m   1065\u001b[0m   },\n\u001b[1;32m   1066\u001b[0m   {\n\u001b[1;32m   1067\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1068\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1069\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/Decoder_Block.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m200\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1071\u001b[0m    ]\n\u001b[1;32m   1072\u001b[0m   },\n\u001b[1;32m   1073\u001b[0m   {\n\u001b[1;32m   1074\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1075\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m71\u001b[39m,\n\u001b[1;32m   1076\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1077\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m   1078\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass DecoderBlock(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Decoder block for a Transformer model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This block consists of a self-attention mechanism, a cross-attention mechanism (attending to encoder output),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    and a feed-forward network. Each sublayer is followed by a residual connection and layer normalization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1087\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            features: int,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self_attention_block: MultiHeadAttentionBlock, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1090\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            cross_attention_block: MultiHeadAttentionBlock,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1091\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            feed_forward_block: FeedForwardBlock,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            dropout: float = 0.1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        ) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Initializes the DecoderBlock with self-attention, cross-attention, feed-forward blocks,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        and residual connections.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self_attention_block (MultiHeadAttentionBlock): Multi-head self-attention mechanism.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            cross_attention_block (MultiHeadAttentionBlock): Cross-attention mechanism to attend to encoder output.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            feed_forward_block (FeedForwardBlock): Feed-forward network.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            dropout (float): Dropout rate to be applied after each sublayer.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.self_attention_block = self_attention_block  # Self-attention mechanism\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.cross_attention_block = cross_attention_block  # Cross-attention mechanism\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.feed_forward_block = feed_forward_block  # Feed-forward network\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(3)])  # Residual connections with dropout\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1110\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x, encoder_output, src_mask, tgt_mask):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1111\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass through the decoder block.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor of shape (batch_size, seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            encoder_output (torch.Tensor): Encoder output tensor of shape (batch_size, seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            src_mask (torch.Tensor): Source mask tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            tgt_mask (torch.Tensor): Target mask tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Output tensor after applying self-attention, cross-attention, feed-forward network, and residual connections.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply the first residual connection with the self-attention block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, tgt_mask))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1125\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply the second residual connection with the cross-attention block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = self.residual_connections[1](x, lambda x: self.cross_attention_block(x, encoder_output, encoder_output, src_mask))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply the third residual connection with the feed-forward block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = self.residual_connections[2](x, lambda x: self.feed_forward_block(x))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return x  # Return the final output tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1133\u001b[0m    ]\n\u001b[1;32m   1134\u001b[0m   },\n\u001b[1;32m   1135\u001b[0m   {\n\u001b[1;32m   1136\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1137\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m72\u001b[39m,\n\u001b[1;32m   1138\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1139\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1140\u001b[0m     {\n\u001b[1;32m   1141\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1142\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1143\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1144\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape: torch.Size([32, 10, 512])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m      ]\n\u001b[1;32m   1146\u001b[0m     }\n\u001b[1;32m   1147\u001b[0m    ],\n\u001b[1;32m   1148\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 512  # Dimension of the model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_heads = 8  # Number of attention heads\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_ff = 2048  # Dimension of the feed-forward layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout = 0.1  # Dropout rate\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 10  # Sequence length\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size = 32  # Batch size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create instances of the attention and feed-forward blocks\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself_attention_block = MultiHeadAttentionBlock(d_model, num_heads, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross_attention_block = MultiHeadAttentionBlock(d_model, num_heads, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create an instance of the DecoderBlock\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1163\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_block = DecoderBlock(d_model, self_attention_block, cross_attention_block, feed_forward_block, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Dummy input tensors\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.randn(batch_size, seq_len, d_model)  # Input tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_output = torch.randn(batch_size, seq_len, d_model)  # Encoder output tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc_mask = torch.ones(batch_size, 1, seq_len, seq_len)  # Source mask tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtgt_mask = torch.ones(batch_size, 1, seq_len, seq_len)  # Target mask tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Forward pass through the DecoderBlock\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = decoder_block(x, encoder_output, src_mask, tgt_mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1174\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1175\u001b[0m    ]\n\u001b[1;32m   1176\u001b[0m   },\n\u001b[1;32m   1177\u001b[0m   {\n\u001b[1;32m   1178\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1179\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1180\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Decoder\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1182\u001b[0m    ]\n\u001b[1;32m   1183\u001b[0m   },\n\u001b[1;32m   1184\u001b[0m   {\n\u001b[1;32m   1185\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1186\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m74\u001b[39m,\n\u001b[1;32m   1187\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1188\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m   1189\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass Decoder(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Decoder for a Transformer model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1194\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This decoder consists of a stack of decoder layers, each containing self-attention, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    cross-attention, and feed-forward networks with residual connections and layer normalization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1197\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, features: int, layers: nn.ModuleList) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1199\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Initializes the Decoder with a list of layers and a layer normalization module.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            features (int): Number of input feautres for layewr normalization\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            layers (nn.ModuleList): List of decoder layers to be included in the decoder.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.layers = layers  # List of decoder layers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.norm = LayerNormalization(features)  # Initialize layer normalization\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1209\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x, encoder_output, src_mask, tgt_mask):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass through the decoder.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor of shape (batch_size, seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            encoder_output (torch.Tensor): Encoder output tensor of shape (batch_size, seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            src_mask (torch.Tensor): Source mask tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1217\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            tgt_mask (torch.Tensor): Target mask tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Output tensor after applying all decoder layers and layer normalization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for layer in self.layers:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1223\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x = layer(x, encoder_output, src_mask, tgt_mask)  # Apply each decoder layer to the input\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1224\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.norm(x)  # Apply layer normalization to the final output\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1226\u001b[0m    ]\n\u001b[1;32m   1227\u001b[0m   },\n\u001b[1;32m   1228\u001b[0m   {\n\u001b[1;32m   1229\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1230\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m77\u001b[39m,\n\u001b[1;32m   1231\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1232\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1233\u001b[0m     {\n\u001b[1;32m   1234\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1235\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1236\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1237\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape: torch.Size([32, 10, 512])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1238\u001b[0m      ]\n\u001b[1;32m   1239\u001b[0m     }\n\u001b[1;32m   1240\u001b[0m    ],\n\u001b[1;32m   1241\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 512  # Dimension of the model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_heads = 8  # Number of attention heads\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_ff = 2048  # Dimension of the feed-forward layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout = 0.1  # Dropout rate\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 10  # Sequence length\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size = 32  # Batch size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create instances of the attention and feed-forward blocks\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself_attention_block = MultiHeadAttentionBlock(d_model, num_heads, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross_attention_block = MultiHeadAttentionBlock(d_model, num_heads, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create a list of decoder blocks\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_blocks = nn.ModuleList([\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    DecoderBlock(d_model, self_attention_block, cross_attention_block, feed_forward_block, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for _ in range(6)  # Number of decoder layers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1260\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create an instance of the Decoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder = Decoder(d_model, decoder_blocks)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Dummy input tensors\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.randn(batch_size, seq_len, d_model)  # Input tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_output = torch.randn(batch_size, seq_len, d_model)  # Encoder output tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc_mask = torch.ones(batch_size, 1, seq_len, seq_len)  # Source mask tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtgt_mask = torch.ones(batch_size, 1, seq_len, seq_len)  # Target mask tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Forward pass through the Decoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = decoder(x, encoder_output, src_mask, tgt_mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1273\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1274\u001b[0m    ]\n\u001b[1;32m   1275\u001b[0m   },\n\u001b[1;32m   1276\u001b[0m   {\n\u001b[1;32m   1277\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1278\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1279\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Projection Layer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m    ]\n\u001b[1;32m   1282\u001b[0m   },\n\u001b[1;32m   1283\u001b[0m   {\n\u001b[1;32m   1284\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1285\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m78\u001b[39m,\n\u001b[1;32m   1286\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1287\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m   1288\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass ProjectionLayer(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Projection layer for a Transformer model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This layer projects the hidden states from the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms d_model dimensionality\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    to the vocabulary size dimensionality and applies a log softmax function.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, d_model: int, vocab_size: int) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Initializes the ProjectionLayer with a linear projection layer.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            d_model (int): Dimensionality of the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms hidden states.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            vocab_size (int): Size of the vocabulary (number of target classes).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.proj = nn.Linear(d_model, vocab_size)  # Linear layer to project to vocabulary size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1306\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x: torch.Tensor) -> torch.Tensor:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1308\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass through the projection layer.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1312\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor of shape (batch_size, seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Output tensor of shape (batch_size, seq_len, vocab_size) with log softmax applied.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # (batch_size, seq_len, d_model) -> (batch_size, seq_len, vocab_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return F.log_softmax(self.proj(x), dim=-1)  # Apply linear projection and log softmax\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1319\u001b[0m    ]\n\u001b[1;32m   1320\u001b[0m   },\n\u001b[1;32m   1321\u001b[0m   {\n\u001b[1;32m   1322\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1323\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m79\u001b[39m,\n\u001b[1;32m   1324\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1325\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1326\u001b[0m     {\n\u001b[1;32m   1327\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1328\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1329\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1330\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape: torch.Size([32, 10, 10000])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1331\u001b[0m      ]\n\u001b[1;32m   1332\u001b[0m     }\n\u001b[1;32m   1333\u001b[0m    ],\n\u001b[1;32m   1334\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1335\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1336\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 512  # Dimensionality of the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms hidden states\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1337\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_size = 10000  # Size of the vocabulary\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 10  # Sequence length\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1339\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size = 32  # Batch size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1341\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create an instance of the ProjectionLayer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1342\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprojection_layer = ProjectionLayer(d_model, vocab_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1343\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Dummy input tensor of shape (batch_size, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.randn(batch_size, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Forward pass through the ProjectionLayer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = projection_layer(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Output tensor should have shape (batch_size, seq_len, vocab_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1351\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1352\u001b[0m    ]\n\u001b[1;32m   1353\u001b[0m   },\n\u001b[1;32m   1354\u001b[0m   {\n\u001b[1;32m   1355\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1356\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1357\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Transformer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1359\u001b[0m    ]\n\u001b[1;32m   1360\u001b[0m   },\n\u001b[1;32m   1361\u001b[0m   {\n\u001b[1;32m   1362\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1363\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1364\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1365\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/model_arch.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m300\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m    ]\n\u001b[1;32m   1367\u001b[0m   },\n\u001b[1;32m   1368\u001b[0m   {\n\u001b[1;32m   1369\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1370\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m80\u001b[39m,\n\u001b[1;32m   1371\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1372\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m   1373\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass Transformer(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            encoder: Encoder, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            decoder: Decoder, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            src_embed: InputEmbeddings, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            tgt_embed: InputEmbeddings,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            src_pos: PositionalEncoding,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            tgt_pos: PositionalEncoding,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            projection_layer: ProjectionLayer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        ) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1388\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.encoder = encoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1389\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.decoder = decoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1390\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.src_embed = src_embed\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.tgt_embed = tgt_embed\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1392\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.src_pos = src_pos\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1393\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.src_tgt = tgt_pos\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.projection_layer = projection_layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def encode(self, src, src_mask):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1397\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        src = self.src_embed(src)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1398\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        src = self.src_pos(src)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1399\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.encoder(src, src_mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1400\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1401\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def decode(self, encoder_output, src_mask, tgt, tgt_mask):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1402\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        tgt = self.src_embed(tgt)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        tgt = self.src_pos(tgt)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1405\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1406\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def project(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1407\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.projection_layer(x)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1408\u001b[0m    ]\n\u001b[1;32m   1409\u001b[0m   },\n\u001b[1;32m   1410\u001b[0m   {\n\u001b[1;32m   1411\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1412\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m81\u001b[39m,\n\u001b[1;32m   1413\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1414\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m   1415\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef build_transformer(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        src_vocab_size: int,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1418\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        tgt_vocab_size: int, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        src_seq_len: int, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1420\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        tgt_seq_len: int, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1421\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        d_model: int=512, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1422\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        N: int=6, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        h: int=8, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        dropout: float=0.1, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        d_ff: int=2048\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    ) -> Transformer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1428\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Create the embedding layers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    src_embed = InputEmbeddings(d_model, src_vocab_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1430\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1432\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Create the positional encoding layers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1433\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    src_pos = PositionalEncoding(d_model, src_seq_len, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1435\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1436\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Create the encoder blocks\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1437\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    encoder_blocks = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1438\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for _ in range(N):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        encoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        encoder_block = EncoderBlock(d_model, encoder_self_attention_block, feed_forward_block, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        encoder_blocks.append(encoder_block)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1443\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1444\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    decoder_blocks = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for _ in range(N):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1446\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        decoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1447\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        decoder_cross_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1448\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1449\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        decoder_block = DecoderBlock(d_model, decoder_self_attention_block, decoder_cross_attention_block, feed_forward_block, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        decoder_blocks.append(decoder_block)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1452\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Create the encoder and decoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    encoder = Encoder(d_model, nn.ModuleList(encoder_blocks))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1454\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    decoder = Decoder(d_model, nn.ModuleList(decoder_blocks))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1455\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1456\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Create the projection layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1457\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1458\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Create the transformer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1460\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1462\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Initialize the parameter\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1463\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for p in transformer.parameters():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if p.dim() > 1:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1465\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            nn.init.xavier_uniform(p)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1466\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1467\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return transformer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1468\u001b[0m    ]\n\u001b[1;32m   1469\u001b[0m   },\n\u001b[1;32m   1470\u001b[0m   {\n\u001b[1;32m   1471\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1472\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m83\u001b[39m,\n\u001b[1;32m   1473\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1474\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1475\u001b[0m     {\n\u001b[1;32m   1476\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1477\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1478\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1479\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mYash Gupta\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mAppData\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLocal\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mTemp\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mipykernel_960\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m2432990575.py:50: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1480\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  nn.init.xavier_uniform(p)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1481\u001b[0m      ]\n\u001b[1;32m   1482\u001b[0m     }\n\u001b[1;32m   1483\u001b[0m    ],\n\u001b[1;32m   1484\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1485\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel = build_transformer(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1486\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        src_vocab_size = 30000,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        tgt_vocab_size = 25000,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1488\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        src_seq_len = 500,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1489\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        tgt_seq_len = 500,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1490\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1491\u001b[0m    ]\n\u001b[1;32m   1492\u001b[0m   }\n\u001b[1;32m   1493\u001b[0m  ],\n\u001b[1;32m   1494\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m   1495\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernelspec\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m   1496\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyf_venv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1497\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1498\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1499\u001b[0m   },\n\u001b[1;32m   1500\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m   1501\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodemirror_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m   1502\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m   1504\u001b[0m    },\n\u001b[1;32m   1505\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_extension\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1506\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmimetype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/x-python\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1507\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1508\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbconvert_exporter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1509\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpygments_lexer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipython3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1510\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.9.11\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1511\u001b[0m   }\n\u001b[1;32m   1512\u001b[0m  },\n\u001b[1;32m   1513\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbformat\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m   1514\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbformat_minor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m   1515\u001b[0m }\n","File \u001b[0;32m~/.pyenv/versions/pfenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.pyenv/versions/pfenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/1898483/transformer_pytorch/experiments/model.ipynb:34\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m {\n\u001b[1;32m      2\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcells\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      3\u001b[0m   {\n\u001b[1;32m      4\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m      6\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# **ATTENTION IS ALL YOU NEED!**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Language Translator\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReference: [Attention is all you need (Transformer) - Model explanation (including math), Inference and Training](https://www.youtube.com/@umarjamilai)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello Readers,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn this project, we are going to implement the transformer from the paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Project Overview\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis notebook will guide you through the following steps:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. **Data Preparation:** Loading and preprocessing the English-Italian translation dataset.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. **Model Architecture:** Building the transformer model as described in the paper.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3. **Training:** Training the transformer model on the dataset.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4. **Evaluation:** Evaluating the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms performance on test data.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5. **Inference:** Translating English sentences to Italian using the trained model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Workflow\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe will start with some helper functions, then usual imports, then directly jump into model architecture, then prepare the dataset for training, and finally perform inference. Variable names used in the code aligns with paper.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms get started!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m    ]\n\u001b[1;32m     37\u001b[0m   },\n\u001b[1;32m     38\u001b[0m   {\n\u001b[1;32m     39\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     41\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Model Architecture\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m    ]\n\u001b[1;32m     44\u001b[0m   },\n\u001b[1;32m     45\u001b[0m   {\n\u001b[1;32m     46\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     47\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     48\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/model_arch.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m300\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m    ]\n\u001b[1;32m     51\u001b[0m   },\n\u001b[1;32m     52\u001b[0m   {\n\u001b[1;32m     53\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     54\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     55\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#### Required imports\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m    ]\n\u001b[1;32m     58\u001b[0m   },\n\u001b[1;32m     59\u001b[0m   {\n\u001b[1;32m     60\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     61\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m6\u001b[39m,\n\u001b[1;32m     62\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     63\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     64\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch.nn as nn\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport math\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch.nn.functional as F\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m    ]\n\u001b[1;32m     70\u001b[0m   },\n\u001b[1;32m     71\u001b[0m   {\n\u001b[1;32m     72\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     73\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     74\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#### Helper Functions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m    ]\n\u001b[1;32m     77\u001b[0m   },\n\u001b[1;32m     78\u001b[0m   {\n\u001b[1;32m     79\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     80\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m7\u001b[39m,\n\u001b[1;32m     81\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     82\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     83\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef count_parameters(model):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Count and print the number of trainable parameters in a model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This function iterates over all parameters in the given model,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    filters those that require gradients (trainable parameters), \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    and prints each parameter\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms count. Finally, it prints the total\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    count of trainable parameters.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        model (torch.nn.Module): The model for which to count parameters.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Example:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        model = YourModel()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        count_parameters(model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    params = [p.numel() for p in model.parameters() if p.requires_grad]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for item in params:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        print(f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{item:>6}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m______\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124msum(params):>6}\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m    ]\n\u001b[1;32m    105\u001b[0m   },\n\u001b[1;32m    106\u001b[0m   {\n\u001b[1;32m    107\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    108\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    109\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Input Embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m    ]\n\u001b[1;32m    112\u001b[0m   },\n\u001b[1;32m    113\u001b[0m   {\n\u001b[1;32m    114\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    115\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    116\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/input_embedding.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m1000\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m    ]\n\u001b[1;32m    119\u001b[0m   },\n\u001b[1;32m    120\u001b[0m   {\n\u001b[1;32m    121\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    122\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m    123\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    124\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    125\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass InputEmbeddings(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Input Embeddings Class\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This class defines the input embedding layer used in the transformer model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    It converts input tokens to their corresponding embeddings and scales them\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    by the square root of the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms dimensionality (d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        d_model (int): The dimensionality of the embeddings.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        vocab_size (int): The size of the vocabulary (i.e., the number of unique tokens).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Methods:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        forward(x): Computes the embeddings for the input tokens and scales them.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, d_model: int, vocab_size: int):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.d_model = d_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.vocab_size = vocab_size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Define the embedding layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.embedding = nn.Embedding(vocab_size, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass for the input embeddings.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor containing token indices.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Scaled embeddings for the input tokens.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Compute embeddings and scale them by sqrt(d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.embedding(x) * math.sqrt(self.d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m    ]\n\u001b[1;32m    161\u001b[0m   },\n\u001b[1;32m    162\u001b[0m   {\n\u001b[1;32m    163\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    164\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m    165\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    166\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    167\u001b[0m     {\n\u001b[1;32m    168\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    169\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/plain\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    170\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Size([10, 50, 512])\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m       ]\n\u001b[1;32m    172\u001b[0m      },\n\u001b[1;32m    173\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m    174\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    175\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecute_result\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     }\n\u001b[1;32m    177\u001b[0m    ],\n\u001b[1;32m    178\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example usage\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 512  # Dimension of the model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_size = 25000  # Maximum length of the sequence\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_tensor = torch.randint(low = 0, high = vocab_size-1, size = (10,50), dtype=torch.int) # 10 lines, 50 words per line\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_embeddings = InputEmbeddings(d_model, vocab_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_embeddings(input_tensor).shape\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m    ]\n\u001b[1;32m    186\u001b[0m   },\n\u001b[1;32m    187\u001b[0m   {\n\u001b[1;32m    188\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    189\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m    190\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    191\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    192\u001b[0m     {\n\u001b[1;32m    193\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    194\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    195\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    196\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m12800000\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    197\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m______\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    198\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m12800000\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m      ]\n\u001b[1;32m    200\u001b[0m     }\n\u001b[1;32m    201\u001b[0m    ],\n\u001b[1;32m    202\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount_parameters(input_embeddings) # weights=> 512*25000\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m    ]\n\u001b[1;32m    205\u001b[0m   },\n\u001b[1;32m    206\u001b[0m   {\n\u001b[1;32m    207\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    208\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    209\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Positional Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m    ]\n\u001b[1;32m    212\u001b[0m   },\n\u001b[1;32m    213\u001b[0m   {\n\u001b[1;32m    214\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    215\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    216\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/Positional_encoding_1.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m1000\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/Positional_encoding_2.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m1000\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m    ]\n\u001b[1;32m    220\u001b[0m   },\n\u001b[1;32m    221\u001b[0m   {\n\u001b[1;32m    222\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m    224\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    225\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    226\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass PositionalEncoding(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Positional Encoding Class\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This class adds positional encoding to the input embeddings to provide \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    the model with information about the relative or absolute position of \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    tokens in the sequence. The implementation includes a dropout layer \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for regularization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        d_model (int): The dimensionality of the embeddings.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        seq_len (int): The maximum length of the input sequences.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        dropout (float): The dropout rate for regularization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        div_term_implementation (str): Specifies the method to compute the \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            division term. Options are \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodified\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Methods:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        forward(x): Adds positional encoding to the input tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, d_model: int, seq_len: int, dropout: float, div_term_implementation: str = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodified\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.d_model = d_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.seq_len = seq_len\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.dropout = nn.Dropout(dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Create a matrix of shape (seq_len, d_model) for positional encodings\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pe = torch.zeros(seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Create a vector of shape (seq_len, 1) for position indices\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Calculate the division term based on the specified implementation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if div_term_implementation == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            div_term = 1.0 / (10000 ** (torch.arange(0, d_model, 2).float() / d_model))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply sine to even indices and cosine to odd indices\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pe[:, 0::2] = torch.sin(position * div_term)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pe[:, 1::2] = torch.cos(position * div_term)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Add an extra dimension for batch size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pe = pe.unsqueeze(0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Register the positional encoding matrix as a buffer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.register_buffer(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, pe)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass for the positional encoding.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor containing embeddings.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Input tensor with added positional encoding.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Add positional encoding to the input tensor and disable gradient computation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = x + (self.pe[:, :x.shape[1],]).requires_grad_(False)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.dropout(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m    ]\n\u001b[1;32m    287\u001b[0m   },\n\u001b[1;32m    288\u001b[0m   {\n\u001b[1;32m    289\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    290\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m25\u001b[39m,\n\u001b[1;32m    291\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    292\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    293\u001b[0m     {\n\u001b[1;32m    294\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    295\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    296\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    297\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Size([32, 100, 512])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m      ]\n\u001b[1;32m    299\u001b[0m     }\n\u001b[1;32m    300\u001b[0m    ],\n\u001b[1;32m    301\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example usage\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 512  # Dimension of the model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_len = 5000  # Maximum length of the sequence\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos_encoder = PositionalEncoding(d_model, max_len, dropout=0.2)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Dummy input tensor with shape (batch size, sequence length, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.zeros(32, 100, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Apply positional encoding\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = pos_encoder(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(x.shape)  # Should output: torch.Size([100, 32, 512])\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m    ]\n\u001b[1;32m    314\u001b[0m   },\n\u001b[1;32m    315\u001b[0m   {\n\u001b[1;32m    316\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    317\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m27\u001b[39m,\n\u001b[1;32m    318\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    319\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    320\u001b[0m     {\n\u001b[1;32m    321\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    322\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    323\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    324\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m______\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    325\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m     0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m      ]\n\u001b[1;32m    327\u001b[0m     }\n\u001b[1;32m    328\u001b[0m    ],\n\u001b[1;32m    329\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount_parameters(pos_encoder)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m    ]\n\u001b[1;32m    332\u001b[0m   },\n\u001b[1;32m    333\u001b[0m   {\n\u001b[1;32m    334\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    335\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    336\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Layer Normalization\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m    ]\n\u001b[1;32m    339\u001b[0m   },\n\u001b[1;32m    340\u001b[0m   {\n\u001b[1;32m    341\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    342\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    343\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/Layer_Normalization.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m1000\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    345\u001b[0m    ]\n\u001b[1;32m    346\u001b[0m   },\n\u001b[1;32m    347\u001b[0m   {\n\u001b[1;32m    348\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    349\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m29\u001b[39m,\n\u001b[1;32m    350\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    351\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    352\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass LayerNormalization(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Layer Normalization Class\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This class applies layer normalization to the input tensor of batch. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Layer normalization normalizes the inputs across the features \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    (i.e., the last dimension) to have mean zero and variance one. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    It also includes learnable parameters for scaling and bias.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        features (int): Number of features in a model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        eps (float): A small value to avoid division by zero during normalization. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                     Default is 10**-6.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Methods:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        forward(x): Applies layer normalization to the input tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, features: int, eps: float = 10**-6):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.eps = eps\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.alpha = nn.Parameter(torch.ones(features))        # Learnable scaling parameter\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.bias = nn.Parameter(torch.zeros(features))         # Learnable bias parameter\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass for the layer normalization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor to be normalized.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Normalized input tensor with learnable scaling and bias.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # x: (batch, seq_len, hidden_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        mean = x.mean(dim=-1, keepdim=True) # (batch, seq_len, 1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        std = x.std(dim=-1, keepdim=True) # (batch, seq_len, 1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply normalization, scaling, and bias\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.alpha * (x - mean) / (std + self.eps) + self.bias\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m    ]\n\u001b[1;32m    393\u001b[0m   },\n\u001b[1;32m    394\u001b[0m   {\n\u001b[1;32m    395\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    396\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m47\u001b[39m,\n\u001b[1;32m    397\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    398\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    399\u001b[0m     {\n\u001b[1;32m    400\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    401\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    402\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    403\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput Shape: torch.Size([16, 500, 512])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    404\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput Shape: torch.Size([16, 500, 512])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    405\u001b[0m      ]\n\u001b[1;32m    406\u001b[0m     }\n\u001b[1;32m    407\u001b[0m    ],\n\u001b[1;32m    408\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example usage\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch = 16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 500\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 512\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Input tensor of shape (batch_size, sequence_length, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.randn(batch, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Instantiate the LayerNormalization class\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer_norm = LayerNormalization(d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Apply layer normalization\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = layer_norm(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mInput Shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, x.shape)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput Shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    422\u001b[0m    ]\n\u001b[1;32m    423\u001b[0m   },\n\u001b[1;32m    424\u001b[0m   {\n\u001b[1;32m    425\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    426\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m48\u001b[39m,\n\u001b[1;32m    427\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    428\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    429\u001b[0m     {\n\u001b[1;32m    430\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    431\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    432\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    433\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   512\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    434\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   512\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    435\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m______\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    436\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  1024\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m      ]\n\u001b[1;32m    438\u001b[0m     }\n\u001b[1;32m    439\u001b[0m    ],\n\u001b[1;32m    440\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount_parameters(layer_norm)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m    ]\n\u001b[1;32m    443\u001b[0m   },\n\u001b[1;32m    444\u001b[0m   {\n\u001b[1;32m    445\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    446\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    447\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Feed Forward Block\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m    ]\n\u001b[1;32m    450\u001b[0m   },\n\u001b[1;32m    451\u001b[0m   {\n\u001b[1;32m    452\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    453\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m49\u001b[39m,\n\u001b[1;32m    454\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    455\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    456\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass FeedForwardBlock(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    FeedForward Block Class\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This class defines a feedforward neural network block used in the \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    transformer model. It consists of two linear transformations with \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    a ReLU activation in between, and dropout for regularization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        d_model (int): The dimensionality of the input and output features.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        d_ff (int): The dimensionality of the intermediate (hidden) features.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        dropout (float): The dropout rate for regularization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Methods:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        forward(x): Applies the feedforward block to the input tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # First linear layer with input size d_model and output size d_ff\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.linear_1 = nn.Linear(d_model, d_ff) # W1 and B1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Dropout layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.dropout = nn.Dropout(dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Second linear layer with input size d_ff and output size d_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.linear_2 = nn.Linear(d_ff, d_model) # W2 and B2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass for the feedforward block.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor with shape (Batch, Seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Output tensor with shape (Batch, Seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply the first linear layer, ReLU activation, dropout, and then the second linear layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # (Batch, Seq_len, d_model) -> (Batch, Seq_len, d_ff) -> (Batch, Seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m    ]\n\u001b[1;32m    496\u001b[0m   },\n\u001b[1;32m    497\u001b[0m   {\n\u001b[1;32m    498\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    499\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m    500\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    501\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    502\u001b[0m     {\n\u001b[1;32m    503\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    504\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    505\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    506\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput Shape: torch.Size([16, 500, 512])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    507\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput Shape: torch.Size([16, 500, 512])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m      ]\n\u001b[1;32m    509\u001b[0m     }\n\u001b[1;32m    510\u001b[0m    ],\n\u001b[1;32m    511\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example usage\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size = 16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 500\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 512\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Input tensor of shape (batch_size, sequence_length, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.randn(batch_size, seq_len, d_model)  # Example input tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Instantiate the FeedForwardBlock class\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_ff = 2048  # Dimension of the feedforward layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout = 0.1  # Dropout rate\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Apply the feedforward block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = feed_forward_block(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mInput Shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, x.shape)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput Shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    529\u001b[0m    ]\n\u001b[1;32m    530\u001b[0m   },\n\u001b[1;32m    531\u001b[0m   {\n\u001b[1;32m    532\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    533\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m51\u001b[39m,\n\u001b[1;32m    534\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    535\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    536\u001b[0m     {\n\u001b[1;32m    537\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    538\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    539\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    540\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1048576\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    541\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  2048\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    542\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1048576\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    543\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   512\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    544\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m______\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    545\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2099712\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m      ]\n\u001b[1;32m    547\u001b[0m     }\n\u001b[1;32m    548\u001b[0m    ],\n\u001b[1;32m    549\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount_parameters(feed_forward_block)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m    ]\n\u001b[1;32m    552\u001b[0m   },\n\u001b[1;32m    553\u001b[0m   {\n\u001b[1;32m    554\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    555\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    556\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# 26th March 10:32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m    ]\n\u001b[1;32m    559\u001b[0m   },\n\u001b[1;32m    560\u001b[0m   {\n\u001b[1;32m    561\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    562\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    563\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Multi-Head Attention\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    565\u001b[0m    ]\n\u001b[1;32m    566\u001b[0m   },\n\u001b[1;32m    567\u001b[0m   {\n\u001b[1;32m    568\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    570\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/Multi_head_attention.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m1200\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m    ]\n\u001b[1;32m    573\u001b[0m   },\n\u001b[1;32m    574\u001b[0m   {\n\u001b[1;32m    575\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    576\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m54\u001b[39m,\n\u001b[1;32m    577\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    578\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    579\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MultiHeadAttentionBlock(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Multi-Head Attention Block Class\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This class implements the multi-head attention mechanism as described \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    in the \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mAttention Is All You Need\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m paper. It allows the model to jointly \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    attend to information from different representation subspaces.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        d_model (int): The dimensionality of the input and output features.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        h (int): The number of attention heads.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        dropout (float): The dropout rate for regularization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Methods:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        forward(q, k, v, mask): Applies multi-head attention to the input tensors.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, d_model: int, h: int, dropout: float):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.d_model = d_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.h = h\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        assert d_model\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mh == 0, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124md_model not divisible by h\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.d_k = d_model//h\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.w_q = nn.Linear(d_model, d_model) #wq\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.w_k = nn.Linear(d_model, d_model) #wk\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.w_v = nn.Linear(d_model, d_model) #wv\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.w_o = nn.Linear(d_model, d_model) #wo\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.dropout = nn.Dropout(dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    @staticmethod \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def attention(query, key, value, mask, dropout: nn.Dropout):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Compute the attention scores and apply the attention mechanism.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            query (torch.Tensor): Query tensor of shape (Batch, h, Seq_Len, d_k).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            key (torch.Tensor): Key tensor of shape (Batch, h, Seq_Len, d_k).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            value (torch.Tensor): Value tensor of shape (Batch, h, Seq_Len, d_k).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            mask (torch.Tensor): Mask tensor to avoid attending to certain positions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            dropout (nn.Dropout): Dropout layer for regularization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: The output tensor after applying attention.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: The attention scores.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        d_k = query.shape[-1]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # (Batch, h, seq_len, d_k) -> (Batch, h, seq_len, seq_len)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if mask is not None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # very low value (indicateing -inf) to positions where mask == 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            attention_scores.masked_fill(mask==0,-1e9)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        attention_scores = attention_scores.softmax(dim = -1) # (Batch, h, seq_len, seq_len)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if dropout is not None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            attention_scores = dropout(attention_scores)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # (batch. h. seq_len, seq_len) -> (batch, h, seq_len, d_k)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # also resturn attention scores used for visualization\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return (attention_scores @ value), attention_scores        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, q, k, v, mask):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass for the multi-head attention block.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            q (torch.Tensor): Query tensor of shape (Batch, Seq_Len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            k (torch.Tensor): Key tensor of shape (Batch, Seq_Len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            v (torch.Tensor): Value tensor of shape (Batch, Seq_Len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            mask (torch.Tensor): Mask tensor to avoid attending to certain positions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: The output tensor after applying multi-head attention.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply linear layers to get query, key, and value tensors\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        query = self.w_q(q) # (Batch, Seq_Len, d_model) -> (Batch, Seq_Len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        key = self.w_k(k) # (Batch, Seq_Len, d_model) -> (Batch, Seq_Len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        value = self.w_v(v) # (Batch, Seq_Len, d_model) -> (Batch, Seq_Len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # (Batch, Seq_Len, d_model) -> (Batch, Seq_Len, h, d_k) -> (Batch, h, Seq_Len, d_k)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1,2)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1,2)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1,2)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply the attention mechanism\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x, self.attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Reshape and transpose back to the original shape\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # (Batch, h, seq_len, d_k) -> (Batch, seq_len, h, d_k) -> (Batch, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = x.transpose(1,2).contiguous().view(x.shape[0], -1, self.h*self.d_k)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply the final linear layer (Batch, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.w_o(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    679\u001b[0m    ]\n\u001b[1;32m    680\u001b[0m   },\n\u001b[1;32m    681\u001b[0m   {\n\u001b[1;32m    682\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    683\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m56\u001b[39m,\n\u001b[1;32m    684\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    685\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    686\u001b[0m     {\n\u001b[1;32m    687\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    688\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    689\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    690\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape: torch.Size([2, 5, 16])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    691\u001b[0m      ]\n\u001b[1;32m    692\u001b[0m     }\n\u001b[1;32m    693\u001b[0m    ],\n\u001b[1;32m    694\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size = 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 5\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh = 4\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout = 0.1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create a random tensor with shape (Batch, Seq_Len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq = torch.rand(batch_size, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk = torch.rand(batch_size, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv = torch.rand(batch_size, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create a mask tensor to avoid attending to certain positions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask = torch.ones(batch_size, 1, seq_len, seq_len)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask[:, :, 2:, :] = 0  # Masking out the last three positions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create a multi-head attention block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmha_block = MultiHeadAttentionBlock(d_model, h, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Apply the multi-head attention block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = mha_block(q, k, v, mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    716\u001b[0m    ]\n\u001b[1;32m    717\u001b[0m   },\n\u001b[1;32m    718\u001b[0m   {\n\u001b[1;32m    719\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    720\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m57\u001b[39m,\n\u001b[1;32m    721\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    722\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    723\u001b[0m     {\n\u001b[1;32m    724\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    725\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    726\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    727\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   256\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    728\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    729\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   256\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    730\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    731\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   256\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    732\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    733\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   256\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    734\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    735\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m______\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    736\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  1088\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    737\u001b[0m      ]\n\u001b[1;32m    738\u001b[0m     }\n\u001b[1;32m    739\u001b[0m    ],\n\u001b[1;32m    740\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount_parameters(mha_block)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    742\u001b[0m    ]\n\u001b[1;32m    743\u001b[0m   },\n\u001b[1;32m    744\u001b[0m   {\n\u001b[1;32m    745\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    746\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    747\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Residual Layer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    749\u001b[0m    ]\n\u001b[1;32m    750\u001b[0m   },\n\u001b[1;32m    751\u001b[0m   {\n\u001b[1;32m    752\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    753\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    754\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/Residual_network.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m300\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    756\u001b[0m    ]\n\u001b[1;32m    757\u001b[0m   },\n\u001b[1;32m    758\u001b[0m   {\n\u001b[1;32m    759\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    760\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m61\u001b[39m,\n\u001b[1;32m    761\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    762\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    763\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass ResidualConnection(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Residual Connection with Layer Normalization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This module adds a residual connection around any given sublayer \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    with layer normalization and dropout applied before the residual \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    connection is added.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        features (int): Number of input features\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        dropout (float): Dropout rate to be applied after the sublayer.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, features: int, dropout: float) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.dropout = nn.Dropout(dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.norm = LayerNormalization(features)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x, sublayer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Apply residual connection to any sublayer.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            sublayer (Callable): A sublayer function or module.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Output tensor after applying the residual connection and dropout.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Norm and Add\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return x + self.dropout(sublayer(self.norm(x)))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    794\u001b[0m    ]\n\u001b[1;32m    795\u001b[0m   },\n\u001b[1;32m    796\u001b[0m   {\n\u001b[1;32m    797\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    798\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m62\u001b[39m,\n\u001b[1;32m    799\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    800\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    801\u001b[0m     {\n\u001b[1;32m    802\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    803\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    804\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    805\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape: torch.Size([16, 500, 512])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    806\u001b[0m      ]\n\u001b[1;32m    807\u001b[0m     }\n\u001b[1;32m    808\u001b[0m    ],\n\u001b[1;32m    809\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example usage\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size = 16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 500\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 512\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout_rate = 0.1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create a random tensor with shape (Batch, Seq_Len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.rand(batch_size, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Define a simple sublayer function for demonstration\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass SimpleSublayer(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, d_model):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.linear = nn.Linear(d_model, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return F.relu(self.linear(x))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msublayer = SimpleSublayer(d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create a residual connection block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresidual_connection = ResidualConnection(d_model, dropout_rate)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Apply the residual connection block with the sublayer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = residual_connection(x, sublayer)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    837\u001b[0m    ]\n\u001b[1;32m    838\u001b[0m   },\n\u001b[1;32m    839\u001b[0m   {\n\u001b[1;32m    840\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    841\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m63\u001b[39m,\n\u001b[1;32m    842\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    843\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    844\u001b[0m     {\n\u001b[1;32m    845\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    846\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    847\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    848\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   512\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    849\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   512\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    850\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m______\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    851\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  1024\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    852\u001b[0m      ]\n\u001b[1;32m    853\u001b[0m     }\n\u001b[1;32m    854\u001b[0m    ],\n\u001b[1;32m    855\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount_parameters(residual_connection)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    857\u001b[0m    ]\n\u001b[1;32m    858\u001b[0m   },\n\u001b[1;32m    859\u001b[0m   {\n\u001b[1;32m    860\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    861\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    862\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Encoder Block\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    864\u001b[0m    ]\n\u001b[1;32m    865\u001b[0m   },\n\u001b[1;32m    866\u001b[0m   {\n\u001b[1;32m    867\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    868\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    869\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/Encoder.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m300\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m    ]\n\u001b[1;32m    872\u001b[0m   },\n\u001b[1;32m    873\u001b[0m   {\n\u001b[1;32m    874\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    875\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m    876\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    877\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    878\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass EncoderBlock(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, features: int, self_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Encoder Block for a Transformer model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        This block consists of a self-attention mechanism followed by a feed-forward network, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        with residual connections and layer normalization applied to each sublayer.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            features (int): Number of input Features\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self_attention_block (MultiHeadAttentionBlock): Multi-head self-attention mechanism.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            feed_forward_block (FeedForwardBlock): Feed-forward network.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            dropout (float): Dropout rate to be applied after each sublayer.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.self_attention_block = self_attention_block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.feed_forward_block = feed_forward_block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(2)])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x, src_mask):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass through the encoder block.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor of shape (batch_size, seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            src_mask (torch.Tensor): Source mask tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Output tensor after applying self-attention, feed-forward network, and residual connections.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply the first residual connection with the self-attention block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, src_mask))  # try without lambda\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply the second residual connection with the feed-forward block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = self.residual_connections[1](x, lambda x: self.feed_forward_block(x))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return x\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    916\u001b[0m    ]\n\u001b[1;32m    917\u001b[0m   },\n\u001b[1;32m    918\u001b[0m   {\n\u001b[1;32m    919\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    920\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m65\u001b[39m,\n\u001b[1;32m    921\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    922\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    923\u001b[0m     {\n\u001b[1;32m    924\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    925\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    926\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    927\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape: torch.Size([2, 5, 16])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    928\u001b[0m      ]\n\u001b[1;32m    929\u001b[0m     }\n\u001b[1;32m    930\u001b[0m    ],\n\u001b[1;32m    931\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size = 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 5\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh = 4\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_ff = 32\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout_rate = 0.1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create random tensors for input and mask\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.rand(batch_size, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    942\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create a mask tensor to avoid attending to certain positions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    943\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask = torch.ones(batch_size, 1, seq_len, seq_len)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask[:, :, 2:, :] = 0  # Masking out the last three positions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Initialize self-attention block and feed-forward block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself_attention_block = MultiHeadAttentionBlock(d_model, h, dropout_rate)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeed_forward_block = FeedForwardBlock(d_model, d_ff, dropout_rate)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Initialize the encoder block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    951\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_block = EncoderBlock(d_model, self_attention_block, feed_forward_block, dropout_rate)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Apply the encoder block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = encoder_block(x, mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    956\u001b[0m    ]\n\u001b[1;32m    957\u001b[0m   },\n\u001b[1;32m    958\u001b[0m   {\n\u001b[1;32m    959\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    960\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    961\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Encoder\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    963\u001b[0m    ]\n\u001b[1;32m    964\u001b[0m   },\n\u001b[1;32m    965\u001b[0m   {\n\u001b[1;32m    966\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    967\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m68\u001b[39m,\n\u001b[1;32m    968\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    969\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    970\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass Encoder(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Encoder block for a Transformer model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This block consists of a stack of layers (e.g., multi-head self-attention and feed-forward networks)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    followed by layer normalization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, features: int, layers: nn.ModuleList) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Initializes the Encoder with a list of layers and a layer normalization module.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            features (int): Number of input features\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            layers (nn.ModuleList): List of layers to be included in the encoder.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.layers = layers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.norm = LayerNormalization(features)  # Initialize layer normalization\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x, mask):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    992\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass through the encoder.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor of shape (batch_size, seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            mask (torch.Tensor): Mask tensor of shape (batch_size, 1, 1, seq_len).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Output tensor after applying all layers and layer normalization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1000\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1001\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for layer in self.layers:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x = layer(x, mask)  # Apply each layer in the list to the input\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.norm(x)  # Apply layer normalization to the final output\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1004\u001b[0m    ]\n\u001b[1;32m   1005\u001b[0m   },\n\u001b[1;32m   1006\u001b[0m   {\n\u001b[1;32m   1007\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1008\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m70\u001b[39m,\n\u001b[1;32m   1009\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1010\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1011\u001b[0m     {\n\u001b[1;32m   1012\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1013\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1014\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1015\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape: torch.Size([2, 5, 16])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1016\u001b[0m      ]\n\u001b[1;32m   1017\u001b[0m     }\n\u001b[1;32m   1018\u001b[0m    ],\n\u001b[1;32m   1019\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size = 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 5\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 16\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh = 4\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_ff = 32\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout_rate = 0.1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1028\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create random tensors for input and mask\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.rand(batch_size, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create a mask tensor to avoid attending to certain positions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask = torch.ones(batch_size, 1, seq_len, seq_len)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask[:, :, 2:, :] = 0  # Masking out the last three positions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Initialize self-attention block and feed-forward block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself_attention_block = MultiHeadAttentionBlock(d_model, h, dropout_rate)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeed_forward_block = FeedForwardBlock(d_model, d_ff, dropout_rate)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Initialize the encoder block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_blocks = nn.ModuleList()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor i in range(10):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    encoder_blocks.append(EncoderBlock(d_model, self_attention_block, feed_forward_block, dropout_rate))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder = Encoder(d_model, encoder_blocks)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Apply the encoder block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = encoder(x, mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m    ]\n\u001b[1;32m   1049\u001b[0m   },\n\u001b[1;32m   1050\u001b[0m   {\n\u001b[1;32m   1051\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1052\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[1;32m   1053\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1054\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m   1055\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m # count_parameters(encoder)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1057\u001b[0m    ]\n\u001b[1;32m   1058\u001b[0m   },\n\u001b[1;32m   1059\u001b[0m   {\n\u001b[1;32m   1060\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1061\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1062\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Decoder_Block\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1064\u001b[0m    ]\n\u001b[1;32m   1065\u001b[0m   },\n\u001b[1;32m   1066\u001b[0m   {\n\u001b[1;32m   1067\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1068\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1069\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/Decoder_Block.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m200\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1071\u001b[0m    ]\n\u001b[1;32m   1072\u001b[0m   },\n\u001b[1;32m   1073\u001b[0m   {\n\u001b[1;32m   1074\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1075\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m71\u001b[39m,\n\u001b[1;32m   1076\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1077\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m   1078\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass DecoderBlock(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Decoder block for a Transformer model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This block consists of a self-attention mechanism, a cross-attention mechanism (attending to encoder output),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    and a feed-forward network. Each sublayer is followed by a residual connection and layer normalization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1087\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            features: int,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self_attention_block: MultiHeadAttentionBlock, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1090\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            cross_attention_block: MultiHeadAttentionBlock,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1091\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            feed_forward_block: FeedForwardBlock,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            dropout: float = 0.1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        ) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Initializes the DecoderBlock with self-attention, cross-attention, feed-forward blocks,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        and residual connections.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self_attention_block (MultiHeadAttentionBlock): Multi-head self-attention mechanism.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            cross_attention_block (MultiHeadAttentionBlock): Cross-attention mechanism to attend to encoder output.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            feed_forward_block (FeedForwardBlock): Feed-forward network.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            dropout (float): Dropout rate to be applied after each sublayer.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.self_attention_block = self_attention_block  # Self-attention mechanism\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.cross_attention_block = cross_attention_block  # Cross-attention mechanism\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.feed_forward_block = feed_forward_block  # Feed-forward network\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(3)])  # Residual connections with dropout\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1110\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x, encoder_output, src_mask, tgt_mask):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1111\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass through the decoder block.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor of shape (batch_size, seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            encoder_output (torch.Tensor): Encoder output tensor of shape (batch_size, seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            src_mask (torch.Tensor): Source mask tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            tgt_mask (torch.Tensor): Target mask tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Output tensor after applying self-attention, cross-attention, feed-forward network, and residual connections.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply the first residual connection with the self-attention block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, tgt_mask))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1125\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply the second residual connection with the cross-attention block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = self.residual_connections[1](x, lambda x: self.cross_attention_block(x, encoder_output, encoder_output, src_mask))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Apply the third residual connection with the feed-forward block\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x = self.residual_connections[2](x, lambda x: self.feed_forward_block(x))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return x  # Return the final output tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1133\u001b[0m    ]\n\u001b[1;32m   1134\u001b[0m   },\n\u001b[1;32m   1135\u001b[0m   {\n\u001b[1;32m   1136\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1137\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m72\u001b[39m,\n\u001b[1;32m   1138\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1139\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1140\u001b[0m     {\n\u001b[1;32m   1141\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1142\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1143\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1144\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape: torch.Size([32, 10, 512])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m      ]\n\u001b[1;32m   1146\u001b[0m     }\n\u001b[1;32m   1147\u001b[0m    ],\n\u001b[1;32m   1148\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 512  # Dimension of the model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_heads = 8  # Number of attention heads\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_ff = 2048  # Dimension of the feed-forward layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout = 0.1  # Dropout rate\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 10  # Sequence length\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size = 32  # Batch size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create instances of the attention and feed-forward blocks\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself_attention_block = MultiHeadAttentionBlock(d_model, num_heads, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross_attention_block = MultiHeadAttentionBlock(d_model, num_heads, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create an instance of the DecoderBlock\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1163\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_block = DecoderBlock(d_model, self_attention_block, cross_attention_block, feed_forward_block, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Dummy input tensors\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.randn(batch_size, seq_len, d_model)  # Input tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_output = torch.randn(batch_size, seq_len, d_model)  # Encoder output tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc_mask = torch.ones(batch_size, 1, seq_len, seq_len)  # Source mask tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtgt_mask = torch.ones(batch_size, 1, seq_len, seq_len)  # Target mask tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Forward pass through the DecoderBlock\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = decoder_block(x, encoder_output, src_mask, tgt_mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1174\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1175\u001b[0m    ]\n\u001b[1;32m   1176\u001b[0m   },\n\u001b[1;32m   1177\u001b[0m   {\n\u001b[1;32m   1178\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1179\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1180\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Decoder\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1182\u001b[0m    ]\n\u001b[1;32m   1183\u001b[0m   },\n\u001b[1;32m   1184\u001b[0m   {\n\u001b[1;32m   1185\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1186\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m74\u001b[39m,\n\u001b[1;32m   1187\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1188\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m   1189\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass Decoder(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Decoder for a Transformer model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1194\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This decoder consists of a stack of decoder layers, each containing self-attention, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    cross-attention, and feed-forward networks with residual connections and layer normalization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1197\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, features: int, layers: nn.ModuleList) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1199\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Initializes the Decoder with a list of layers and a layer normalization module.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            features (int): Number of input feautres for layewr normalization\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            layers (nn.ModuleList): List of decoder layers to be included in the decoder.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.layers = layers  # List of decoder layers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.norm = LayerNormalization(features)  # Initialize layer normalization\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1209\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x, encoder_output, src_mask, tgt_mask):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass through the decoder.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor of shape (batch_size, seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            encoder_output (torch.Tensor): Encoder output tensor of shape (batch_size, seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            src_mask (torch.Tensor): Source mask tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1217\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            tgt_mask (torch.Tensor): Target mask tensor.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Output tensor after applying all decoder layers and layer normalization.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for layer in self.layers:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1223\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x = layer(x, encoder_output, src_mask, tgt_mask)  # Apply each decoder layer to the input\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1224\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.norm(x)  # Apply layer normalization to the final output\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1226\u001b[0m    ]\n\u001b[1;32m   1227\u001b[0m   },\n\u001b[1;32m   1228\u001b[0m   {\n\u001b[1;32m   1229\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1230\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m77\u001b[39m,\n\u001b[1;32m   1231\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1232\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1233\u001b[0m     {\n\u001b[1;32m   1234\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1235\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1236\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1237\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape: torch.Size([32, 10, 512])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1238\u001b[0m      ]\n\u001b[1;32m   1239\u001b[0m     }\n\u001b[1;32m   1240\u001b[0m    ],\n\u001b[1;32m   1241\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 512  # Dimension of the model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_heads = 8  # Number of attention heads\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_ff = 2048  # Dimension of the feed-forward layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout = 0.1  # Dropout rate\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 10  # Sequence length\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size = 32  # Batch size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create instances of the attention and feed-forward blocks\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself_attention_block = MultiHeadAttentionBlock(d_model, num_heads, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross_attention_block = MultiHeadAttentionBlock(d_model, num_heads, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create a list of decoder blocks\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_blocks = nn.ModuleList([\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    DecoderBlock(d_model, self_attention_block, cross_attention_block, feed_forward_block, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for _ in range(6)  # Number of decoder layers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1260\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create an instance of the Decoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder = Decoder(d_model, decoder_blocks)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Dummy input tensors\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.randn(batch_size, seq_len, d_model)  # Input tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_output = torch.randn(batch_size, seq_len, d_model)  # Encoder output tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc_mask = torch.ones(batch_size, 1, seq_len, seq_len)  # Source mask tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtgt_mask = torch.ones(batch_size, 1, seq_len, seq_len)  # Target mask tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Forward pass through the Decoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = decoder(x, encoder_output, src_mask, tgt_mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1273\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1274\u001b[0m    ]\n\u001b[1;32m   1275\u001b[0m   },\n\u001b[1;32m   1276\u001b[0m   {\n\u001b[1;32m   1277\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1278\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1279\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Projection Layer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m    ]\n\u001b[1;32m   1282\u001b[0m   },\n\u001b[1;32m   1283\u001b[0m   {\n\u001b[1;32m   1284\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1285\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m78\u001b[39m,\n\u001b[1;32m   1286\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1287\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m   1288\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass ProjectionLayer(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Projection layer for a Transformer model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    This layer projects the hidden states from the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms d_model dimensionality\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    to the vocabulary size dimensionality and applies a log softmax function.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, d_model: int, vocab_size: int) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Initializes the ProjectionLayer with a linear projection layer.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            d_model (int): Dimensionality of the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms hidden states.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            vocab_size (int): Size of the vocabulary (number of target classes).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.proj = nn.Linear(d_model, vocab_size)  # Linear layer to project to vocabulary size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1306\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, x: torch.Tensor) -> torch.Tensor:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1308\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass through the projection layer.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1312\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x (torch.Tensor): Input tensor of shape (batch_size, seq_len, d_model).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Returns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            torch.Tensor: Output tensor of shape (batch_size, seq_len, vocab_size) with log softmax applied.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # (batch_size, seq_len, d_model) -> (batch_size, seq_len, vocab_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return F.log_softmax(self.proj(x), dim=-1)  # Apply linear projection and log softmax\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1319\u001b[0m    ]\n\u001b[1;32m   1320\u001b[0m   },\n\u001b[1;32m   1321\u001b[0m   {\n\u001b[1;32m   1322\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1323\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m79\u001b[39m,\n\u001b[1;32m   1324\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1325\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1326\u001b[0m     {\n\u001b[1;32m   1327\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1328\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1329\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1330\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape: torch.Size([32, 10, 10000])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1331\u001b[0m      ]\n\u001b[1;32m   1332\u001b[0m     }\n\u001b[1;32m   1333\u001b[0m    ],\n\u001b[1;32m   1334\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1335\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Example\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1336\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model = 512  # Dimensionality of the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms hidden states\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1337\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_size = 10000  # Size of the vocabulary\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len = 10  # Sequence length\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1339\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size = 32  # Batch size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1341\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create an instance of the ProjectionLayer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1342\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprojection_layer = ProjectionLayer(d_model, vocab_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1343\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Dummy input tensor of shape (batch_size, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = torch.randn(batch_size, seq_len, d_model)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Forward pass through the ProjectionLayer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput = projection_layer(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Output tensor should have shape (batch_size, seq_len, vocab_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1351\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, output.shape)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1352\u001b[0m    ]\n\u001b[1;32m   1353\u001b[0m   },\n\u001b[1;32m   1354\u001b[0m   {\n\u001b[1;32m   1355\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1356\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1357\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Transformer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1359\u001b[0m    ]\n\u001b[1;32m   1360\u001b[0m   },\n\u001b[1;32m   1361\u001b[0m   {\n\u001b[1;32m   1362\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1363\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1364\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1365\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mimages/model_arch.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m alt=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m300\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m/>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m    ]\n\u001b[1;32m   1367\u001b[0m   },\n\u001b[1;32m   1368\u001b[0m   {\n\u001b[1;32m   1369\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1370\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m80\u001b[39m,\n\u001b[1;32m   1371\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1372\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m   1373\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass Transformer(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            encoder: Encoder, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            decoder: Decoder, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            src_embed: InputEmbeddings, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            tgt_embed: InputEmbeddings,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            src_pos: PositionalEncoding,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            tgt_pos: PositionalEncoding,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            projection_layer: ProjectionLayer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        ) -> None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1388\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.encoder = encoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1389\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.decoder = decoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1390\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.src_embed = src_embed\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.tgt_embed = tgt_embed\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1392\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.src_pos = src_pos\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1393\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.src_tgt = tgt_pos\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.projection_layer = projection_layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def encode(self, src, src_mask):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1397\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        src = self.src_embed(src)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1398\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        src = self.src_pos(src)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1399\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.encoder(src, src_mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1400\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1401\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def decode(self, encoder_output, src_mask, tgt, tgt_mask):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1402\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        tgt = self.src_embed(tgt)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        tgt = self.src_pos(tgt)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1405\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1406\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def project(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1407\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.projection_layer(x)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1408\u001b[0m    ]\n\u001b[1;32m   1409\u001b[0m   },\n\u001b[1;32m   1410\u001b[0m   {\n\u001b[1;32m   1411\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1412\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m81\u001b[39m,\n\u001b[1;32m   1413\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1414\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m   1415\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef build_transformer(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        src_vocab_size: int,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1418\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        tgt_vocab_size: int, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        src_seq_len: int, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1420\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        tgt_seq_len: int, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1421\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        d_model: int=512, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1422\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        N: int=6, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        h: int=8, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        dropout: float=0.1, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        d_ff: int=2048\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    ) -> Transformer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1428\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Create the embedding layers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    src_embed = InputEmbeddings(d_model, src_vocab_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1430\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1432\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Create the positional encoding layers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1433\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    src_pos = PositionalEncoding(d_model, src_seq_len, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1435\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1436\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Create the encoder blocks\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1437\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    encoder_blocks = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1438\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for _ in range(N):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        encoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        encoder_block = EncoderBlock(d_model, encoder_self_attention_block, feed_forward_block, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        encoder_blocks.append(encoder_block)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1443\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1444\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    decoder_blocks = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for _ in range(N):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1446\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        decoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1447\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        decoder_cross_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1448\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1449\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        decoder_block = DecoderBlock(d_model, decoder_self_attention_block, decoder_cross_attention_block, feed_forward_block, dropout)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        decoder_blocks.append(decoder_block)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1452\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Create the encoder and decoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    encoder = Encoder(d_model, nn.ModuleList(encoder_blocks))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1454\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    decoder = Decoder(d_model, nn.ModuleList(decoder_blocks))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1455\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1456\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Create the projection layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1457\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1458\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Create the transformer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1460\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1462\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Initialize the parameter\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1463\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for p in transformer.parameters():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if p.dim() > 1:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1465\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            nn.init.xavier_uniform(p)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1466\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1467\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return transformer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1468\u001b[0m    ]\n\u001b[1;32m   1469\u001b[0m   },\n\u001b[1;32m   1470\u001b[0m   {\n\u001b[1;32m   1471\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1472\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m83\u001b[39m,\n\u001b[1;32m   1473\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m   1474\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1475\u001b[0m     {\n\u001b[1;32m   1476\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1477\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1478\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1479\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mYash Gupta\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mAppData\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLocal\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mTemp\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mipykernel_960\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m2432990575.py:50: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1480\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  nn.init.xavier_uniform(p)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1481\u001b[0m      ]\n\u001b[1;32m   1482\u001b[0m     }\n\u001b[1;32m   1483\u001b[0m    ],\n\u001b[1;32m   1484\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   1485\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel = build_transformer(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1486\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        src_vocab_size = 30000,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        tgt_vocab_size = 25000,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1488\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        src_seq_len = 500,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1489\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        tgt_seq_len = 500,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1490\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1491\u001b[0m    ]\n\u001b[1;32m   1492\u001b[0m   }\n\u001b[1;32m   1493\u001b[0m  ],\n\u001b[1;32m   1494\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m   1495\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernelspec\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m   1496\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyf_venv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1497\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1498\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1499\u001b[0m   },\n\u001b[1;32m   1500\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m   1501\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodemirror_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m   1502\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m   1504\u001b[0m    },\n\u001b[1;32m   1505\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_extension\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1506\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmimetype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/x-python\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1507\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1508\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbconvert_exporter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1509\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpygments_lexer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipython3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1510\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.9.11\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1511\u001b[0m   }\n\u001b[1;32m   1512\u001b[0m  },\n\u001b[1;32m   1513\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbformat\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m   1514\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbformat_minor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m   1515\u001b[0m }\n","File \u001b[0;32m~/.pyenv/versions/pfenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.pyenv/versions/pfenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.pyenv/versions/pfenv/lib/python3.9/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.pyenv/versions/pfenv/lib/python3.9/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mIndexError\u001b[0m: index out of range in self"]}],"source":["config = get_config()\n","custom_trainer(config)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-26T21:39:35.747897Z","iopub.status.idle":"2024-06-26T21:39:35.748230Z","shell.execute_reply":"2024-06-26T21:39:35.748085Z","shell.execute_reply.started":"2024-06-26T21:39:35.748071Z"},"trusted":true},"outputs":[],"source":["epoch = 0\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.11"}},"nbformat":4,"nbformat_minor":4}
